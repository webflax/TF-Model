{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "H1F56lS_93TS",
   "metadata": {
    "id": "H1F56lS_93TS"
   },
   "source": [
    "# lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94bd2b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:29.385315Z",
     "iopub.status.busy": "2021-11-09T08:22:29.384708Z",
     "iopub.status.idle": "2021-11-09T08:22:37.325011Z",
     "shell.execute_reply": "2021-11-09T08:22:37.325524Z",
     "shell.execute_reply.started": "2021-11-09T08:11:07.476205Z"
    },
    "id": "94bd2b0c",
    "papermill": {
     "duration": 7.986193,
     "end_time": "2021-11-09T08:22:37.325835",
     "exception": false,
     "start_time": "2021-11-09T08:22:29.339642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
    "\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Activation, BatchNormalization\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HfXgO1eM90Iq",
   "metadata": {
    "id": "HfXgO1eM90Iq"
   },
   "source": [
    "# preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gaAHbz6gBbAe",
   "metadata": {
    "id": "gaAHbz6gBbAe"
   },
   "outputs": [],
   "source": [
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xGYj63_oMPEu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGYj63_oMPEu",
    "outputId": "7ae5ac4d-1389-40c3-acd4-3f0c84c71ac6"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"btc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300b773c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:37.474046Z",
     "iopub.status.busy": "2021-11-09T08:22:37.473162Z",
     "iopub.status.idle": "2021-11-09T08:22:43.282686Z",
     "shell.execute_reply": "2021-11-09T08:22:43.283134Z",
     "shell.execute_reply.started": "2021-11-09T07:52:07.794604Z"
    },
    "id": "300b773c",
    "outputId": "4829e8f0-e8c8-4a23-e490-22902d79535b",
    "papermill": {
     "duration": 5.849088,
     "end_time": "2021-11-09T08:22:43.283293",
     "exception": false,
     "start_time": "2021-11-09T08:22:37.434205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume BTC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-11-28</th>\n",
       "      <td>363.59</td>\n",
       "      <td>381.34</td>\n",
       "      <td>360.57</td>\n",
       "      <td>376.28</td>\n",
       "      <td>3220878.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29</th>\n",
       "      <td>376.42</td>\n",
       "      <td>386.60</td>\n",
       "      <td>372.25</td>\n",
       "      <td>376.72</td>\n",
       "      <td>2746157.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-30</th>\n",
       "      <td>376.57</td>\n",
       "      <td>381.99</td>\n",
       "      <td>373.32</td>\n",
       "      <td>373.34</td>\n",
       "      <td>1145566.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-01</th>\n",
       "      <td>376.40</td>\n",
       "      <td>382.31</td>\n",
       "      <td>373.03</td>\n",
       "      <td>378.39</td>\n",
       "      <td>2520662.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-02</th>\n",
       "      <td>378.39</td>\n",
       "      <td>382.86</td>\n",
       "      <td>375.23</td>\n",
       "      <td>379.25</td>\n",
       "      <td>2593576.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open    high     low   close  Volume BTC\n",
       "date                                                  \n",
       "2014-11-28  363.59  381.34  360.57  376.28  3220878.18\n",
       "2014-11-29  376.42  386.60  372.25  376.72  2746157.05\n",
       "2014-11-30  376.57  381.99  373.32  373.34  1145566.61\n",
       "2014-12-01  376.40  382.31  373.03  378.39  2520662.37\n",
       "2014-12-02  378.39  382.86  375.23  379.25  2593576.46"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc = pd.read_csv(path_to_file, skiprows=1)\n",
    "btc = btc[::-1]\n",
    "# btc = btc[2100:]\n",
    "btc = btc.astype({'date': 'datetime64'}).set_index('date')\n",
    "btc = btc.drop(['unix', 'symbol','Volume USD'], axis=1)\n",
    "df = btc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369485c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.855884Z",
     "iopub.status.busy": "2021-11-09T08:22:45.855251Z",
     "iopub.status.idle": "2021-11-09T08:23:07.129023Z",
     "shell.execute_reply": "2021-11-09T08:23:07.129522Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.654405Z"
    },
    "id": "369485c9",
    "outputId": "b5eeb2e9-3df7-4bc0-9c8b-ea85bb8dff72",
    "papermill": {
     "duration": 21.316539,
     "end_time": "2021-11-09T08:23:07.129743",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.813204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Bitcoin Weighted Price'}, xlabel='date'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# btc_input_df_datetype.set_index(\"time\").close.plot(figsize=(24,7), title=\"Bitcoin Weighted Price\")\n",
    "btc.close.plot(figsize=(24,7), title=\"Bitcoin Weighted Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bbcc18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = (df.iloc[1:].reset_index(drop=True).copy()/df.iloc[:-1].reset_index(drop=True).copy())\n",
    "dff_y = (df.iloc[1:].reset_index(drop=True).copy()/df.iloc[:-1].reset_index(drop=True).copy())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "dff.open = scaler.fit_transform(dff.open.values.reshape(-1,1))\n",
    "\n",
    "dff.high = scaler.fit_transform(dff.high.values.reshape(-1,1))\n",
    "\n",
    "dff.low = scaler.fit_transform(dff.low.values.reshape(-1,1))\n",
    "\n",
    "dff.close = scaler.fit_transform(dff.close.values.reshape(-1,1))\n",
    "\n",
    "dff = dff.drop('Volume BTC',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uXX2Q2TSwnve",
   "metadata": {
    "id": "uXX2Q2TSwnve",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2526, 90, 4)\n",
      "(2526,)\n",
      "(18, 90, 4)\n",
      "(18,)\n",
      "[1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.26700412e-01,  3.34351871e-01,  7.26474654e-01,\n",
       "        -3.09347904e-02],\n",
       "       [-5.05742831e-02, -4.06774162e-01,  9.44305260e-03,\n",
       "        -2.86427020e-01],\n",
       "       [-7.19459590e-02, -3.90000848e-02, -7.92478615e-02,\n",
       "         2.80376358e-01],\n",
       "       [ 7.23459270e-02, -2.16835225e-02,  8.28796554e-02,\n",
       "        -3.13603506e-03],\n",
       "       [-3.44493313e-03, -5.26033568e-02, -1.25114057e-01,\n",
       "        -2.31777013e-01],\n",
       "       [-2.31653925e-01, -3.64859259e-01, -9.83377935e-01,\n",
       "        -8.27537683e-01],\n",
       "       [-8.26288987e-01, -1.46782339e-01,  2.08161475e-01,\n",
       "         6.12193184e-01],\n",
       "       [ 6.10721705e-01, -1.31774029e-01,  4.28118685e-01,\n",
       "        -5.23309235e-02],\n",
       "       [-5.25468746e-02, -2.41561220e-02,  6.06466185e-02,\n",
       "         6.05086784e-02],\n",
       "       [ 6.00795324e-02, -6.69578974e-02, -6.17588779e-01,\n",
       "        -8.79939825e-01],\n",
       "       [-8.78592122e-01, -9.77024220e-01, -1.43480969e+00,\n",
       "        -1.03601354e+00],\n",
       "       [-1.03437096e+00, -9.88820110e-01,  1.69838542e-01,\n",
       "        -2.30026873e-01],\n",
       "       [-2.29907092e-01,  8.07721328e-01, -5.80149461e-01,\n",
       "         1.11722898e-03],\n",
       "       [ 8.00294952e-04, -5.24941836e-01,  5.25801390e-01,\n",
       "         3.36648544e-01],\n",
       "       [ 3.35697669e-01, -3.55663452e-01, -1.28085401e-01,\n",
       "        -2.75734008e-01],\n",
       "       [-2.75527869e-01, -3.04267681e-01,  7.47138395e-02,\n",
       "        -1.52146800e-01],\n",
       "       [-1.52174163e-01, -2.11330217e-01,  2.38482715e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -1.45953856e+00,\n",
       "        -1.51006861e+00],\n",
       "       [-1.39694568e+00, -1.23009376e+00, -1.14757237e+00,\n",
       "        -7.41318401e-01],\n",
       "       [-8.37183010e-01, -9.53421753e-01, -8.49443633e-01,\n",
       "        -7.61018729e-01],\n",
       "       [-9.08885120e-01, -5.59643129e-01,  1.08467469e-01,\n",
       "         4.10097981e-01],\n",
       "       [ 4.86073239e-01,  1.10756905e+00,  6.83901078e-01,\n",
       "         8.89481617e-01],\n",
       "       [ 1.15611634e+00, -6.48717923e-02,  1.13060882e-01,\n",
       "        -5.82585212e-01],\n",
       "       [-8.42361881e-01,  2.42686010e-02,  2.49643984e-02,\n",
       "         5.14169596e-01],\n",
       "       [ 5.85512097e-01,  3.68271281e-01,  5.15947182e-01,\n",
       "         3.18426572e-01],\n",
       "       [ 4.32386947e-01, -2.32310552e-01, -5.47691240e-01,\n",
       "        -1.06287479e+00],\n",
       "       [-1.26039573e+00, -1.15512677e+00, -3.85092451e-01,\n",
       "        -2.75455104e-01],\n",
       "       [-2.11032411e-01,  6.27454575e-01, -5.96113369e-02,\n",
       "         8.45908959e-01],\n",
       "       [ 8.82937705e-01, -1.52544636e-01, -4.44715670e-01,\n",
       "        -1.20170895e+00],\n",
       "       [-1.20628119e+00, -1.05660697e+00, -9.23369017e-02,\n",
       "        -1.37757849e-03],\n",
       "       [-1.68979892e-03, -1.08374157e-02, -2.99389989e-02,\n",
       "        -2.07589042e-01],\n",
       "       [-2.07511654e-01, -3.66492366e-01, -1.85881738e-01,\n",
       "        -2.87686485e-01],\n",
       "       [-2.87457764e-01,  2.30701382e-01, -6.31205366e-03,\n",
       "         5.29971650e-01],\n",
       "       [ 5.28655518e-01,  2.69136073e-02,  8.89513149e-02,\n",
       "        -2.92395240e-01],\n",
       "       [-2.92157623e-01, -4.21339576e-01, -1.10109987e-01,\n",
       "        -4.44645459e-02],\n",
       "       [-4.46953594e-02, -1.02229735e-01, -2.15961522e+00,\n",
       "        -2.48804841e+00],\n",
       "       [-2.48366241e+00, -2.49994655e+00, -2.61729669e+00,\n",
       "        -1.94449425e+00],\n",
       "       [-1.94113522e+00, -1.03860585e+00,  6.95967926e-01,\n",
       "         1.09918214e+00],\n",
       "       [ 1.09679056e+00, -3.92483623e-01,  1.22002546e+00,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -6.03785012e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -6.03785012e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -6.03785012e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -6.03785012e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.05943765e-02, -6.31410128e-02, -6.03785012e-02,\n",
       "        -6.03936589e-02],\n",
       "       [-6.41983754e-01, -5.18099035e-01, -1.22401645e+00,\n",
       "        -8.46755040e-01],\n",
       "       [-2.68896902e-01, -4.55582539e-01, -4.44218377e+00,\n",
       "        -4.49090977e+00],\n",
       "       [-4.48273963e+00, -4.12002256e+00, -7.21264688e+00,\n",
       "        -6.78604358e+00],\n",
       "       [-6.77353711e+00,  3.12538358e-01,  1.32629662e+00,\n",
       "         7.21904929e+00],\n",
       "       [ 8.13018605e+00, -1.38758690e+00,  5.50944956e+00,\n",
       "        -3.27027642e-01],\n",
       "       [-1.01713109e+00, -1.39456921e+00, -7.80367104e-01,\n",
       "        -8.53000032e-01],\n",
       "       [-8.51703228e-01,  1.17707747e+00,  2.99867947e-01,\n",
       "         1.36479993e+00],\n",
       "       [ 1.18974871e+00, -2.00737982e-01,  1.51897933e+00,\n",
       "         5.90216881e-01],\n",
       "       [ 8.71946712e-01, -4.67477860e-01, -7.29338224e-01,\n",
       "        -7.34119196e-01],\n",
       "       [-8.40895571e-01,  1.39995718e+00,  3.02815790e-01,\n",
       "         2.02944896e+00],\n",
       "       [ 2.02529977e+00,  1.20840347e+00,  2.42912436e+00,\n",
       "         4.25628290e-01],\n",
       "       [ 4.24509300e-01,  5.74342107e-02, -1.09817608e-01,\n",
       "        -5.71499651e-02],\n",
       "       [-5.73568112e-02,  1.13638653e+00,  4.22097394e-01,\n",
       "         1.77313851e+00],\n",
       "       [ 1.76947358e+00,  7.44933405e-01,  1.13287963e+00,\n",
       "         2.52008177e-01],\n",
       "       [ 2.51217219e-01,  5.86855007e+00,  1.12330732e+00,\n",
       "         1.57306488e+00],\n",
       "       [ 1.56977797e+00, -2.98208470e+00, -1.01918494e+00,\n",
       "        -6.68944321e-01],\n",
       "       [-6.67995266e-01, -1.31099132e+00, -1.77801538e+00,\n",
       "        -2.62669706e+00],\n",
       "       [-2.62204910e+00, -2.68802448e+00, -6.95844712e-01,\n",
       "        -2.15048183e-01],\n",
       "       [-2.14956702e-01,  2.70036539e-01,  7.41215351e-01,\n",
       "        -2.91125419e-01],\n",
       "       [-2.90890201e-01, -1.26063440e+00, -1.29062676e+00,\n",
       "        -1.64387220e+00],\n",
       "       [-1.64108115e+00, -1.78016198e+00, -8.78888604e-01,\n",
       "        -4.27917056e-01],\n",
       "       [-4.27423388e-01,  2.69971401e+00,  6.75986465e-01,\n",
       "         2.65708584e+00],\n",
       "       [ 2.65175082e+00,  2.23866686e-01,  9.56258361e-01,\n",
       "        -1.18467972e+00],\n",
       "       [-1.18275625e+00, -1.64203555e+00, -4.69583671e-01,\n",
       "        -9.91772131e-02],\n",
       "       [-9.93046545e-02, -3.20128050e-01, -7.64745429e-01,\n",
       "        -1.17020373e+00],\n",
       "       [-1.18935417e+00, -4.50831384e-01,  8.85676085e-02,\n",
       "         6.22246938e-01],\n",
       "       [ 7.00218290e-01,  6.10534211e-01,  7.10325055e-01,\n",
       "         5.87282697e-01],\n",
       "       [ 4.94383000e-01,  1.55040986e-01, -2.87107979e-01,\n",
       "        -5.47475082e-01],\n",
       "       [-5.13272091e-01, -9.16937230e-01, -5.80025279e-01,\n",
       "        -4.50324654e-01],\n",
       "       [-4.49788651e-01, -5.71932282e-01, -6.03785012e-02,\n",
       "        -3.41417633e-02],\n",
       "       [-3.43920803e-02,  1.22485087e-01,  2.77432016e-01,\n",
       "        -2.69050008e-01],\n",
       "       [-2.19920590e-01, -1.09572970e-01, -4.03210210e-02,\n",
       "         3.23613188e-01],\n",
       "       [ 3.34534580e-01,  2.42756138e+00,  2.95904732e-01,\n",
       "         1.57034768e+00],\n",
       "       [ 1.51802118e+00,  1.95354739e+00,  1.64371386e+00,\n",
       "         2.17744376e+00],\n",
       "       [ 2.06029322e+00,  6.68103474e-01, -9.98580754e-01,\n",
       "        -2.39406304e+00],\n",
       "       [-2.30906389e+00, -2.73582151e+00,  9.42715452e-02,\n",
       "         2.13053755e-01],\n",
       "       [ 2.12336396e-01,  8.38786451e-01,  2.37426608e-01,\n",
       "         8.35275384e-01],\n",
       "       [ 8.33382422e-01, -2.69327650e-01, -3.62982191e-02,\n",
       "        -1.00347398e+00],\n",
       "       [-8.39706221e-01, -2.95314219e-01,  2.97330214e-01,\n",
       "         6.74691367e-01],\n",
       "       [ 2.80506823e-01,  4.01448350e-01,  3.26153836e-01,\n",
       "         2.95690415e-01],\n",
       "       [ 4.50480452e-01, -2.34453143e-01,  4.05326430e-01,\n",
       "        -8.39382278e-02],\n",
       "       [-6.77646403e-02, -7.01276327e-02, -1.20721918e+00,\n",
       "        -1.00203277e+00],\n",
       "       [-9.55083765e-01, -8.50491082e-01, -1.05307144e-01,\n",
       "         1.78036385e-01],\n",
       "       [ 2.54941026e-01, -3.67974358e-02,  3.84506532e-01,\n",
       "         2.07982476e-02],\n",
       "       [-3.01663512e-02, -9.54422382e-02, -9.12173367e-02,\n",
       "        -2.38021611e-01],\n",
       "       [-2.67045274e-01, -3.09863948e-01, -2.65202816e-01,\n",
       "        -1.98000782e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ = 90\n",
    "def train_test_split(df):\n",
    "    split_row = len(df) - int(0.04 * len(df))\n",
    "    train_data = df.iloc[:split_row]\n",
    "    test_data = df.iloc[split_row:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def extract_windows_data(df):\n",
    "    window_data = []\n",
    "    for idx in range(len(df) - len_):\n",
    "        tmp = df[idx: (idx + len_)].copy()\n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)\n",
    "\n",
    "def prepare_data(df,dff_y):\n",
    "    train_data, test_data = train_test_split(df)\n",
    "    train_data_, test_data_ = train_test_split(dff_y)\n",
    "    X_train = extract_windows_data(train_data)\n",
    "    X_test = extract_windows_data(test_data)\n",
    "    y_train = train_data_['close'][len_:].values\n",
    "    y_test = test_data_['close'][len_:].values\n",
    "    y_train[y_train > 1] = 1\n",
    "    y_train[y_train < 1] = 0\n",
    "    y_test[y_test > 1] = 1\n",
    "    y_test[y_test < 1] = 0\n",
    "    return train_data, test_data, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "train, test, X_train, X_test, y_train, y_test = prepare_data(dff,dff_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[:2])\n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lLbwlWzN8P6-",
   "metadata": {
    "id": "lLbwlWzN8P6-"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c247041",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:01.286885Z",
     "iopub.status.busy": "2021-11-09T08:24:01.285918Z",
     "iopub.status.idle": "2021-11-09T08:24:01.746820Z",
     "shell.execute_reply": "2021-11-09T08:24:01.747339Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.553350Z"
    },
    "id": "0c247041",
    "outputId": "394e1cda-e0d1-434d-c706-63931f58d66c",
    "papermill": {
     "duration": 0.51592,
     "end_time": "2021-11-09T08:24:01.747513",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.231593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 90, 512)           1058816   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 90, 512)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,879,297\n",
      "Trainable params: 1,879,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=128))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51ba6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26563652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_path = 'my_best_model_.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             monitor='loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737a2ede",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:01.859939Z",
     "iopub.status.busy": "2021-11-09T08:24:01.859233Z",
     "iopub.status.idle": "2021-11-09T08:24:34.491023Z",
     "shell.execute_reply": "2021-11-09T08:24:34.491550Z",
     "shell.execute_reply.started": "2021-11-09T07:53:29.074954Z"
    },
    "id": "737a2ede",
    "outputId": "d6da5595-d5d7-41e3-f40f-e8fea0ae7fbf",
    "papermill": {
     "duration": 32.69245,
     "end_time": "2021-11-09T08:24:34.491782",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.799332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5428\n",
      "Epoch 1: loss improved from inf to 0.69341, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 65s 3s/step - loss: 0.6934 - accuracy: 0.5428 - val_loss: 0.7082 - val_accuracy: 0.3889\n",
      "Epoch 2/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.5408\n",
      "Epoch 2: loss improved from 0.69341 to 0.69037, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6904 - accuracy: 0.5408 - val_loss: 0.7030 - val_accuracy: 0.4444\n",
      "Epoch 3/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5368\n",
      "Epoch 3: loss improved from 0.69037 to 0.68959, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.6896 - accuracy: 0.5368 - val_loss: 0.7155 - val_accuracy: 0.4444\n",
      "Epoch 4/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5380\n",
      "Epoch 4: loss did not improve from 0.68959\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.6911 - accuracy: 0.5380 - val_loss: 0.7130 - val_accuracy: 0.4444\n",
      "Epoch 5/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5424\n",
      "Epoch 5: loss did not improve from 0.68959\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.6896 - accuracy: 0.5424 - val_loss: 0.7012 - val_accuracy: 0.5000\n",
      "Epoch 6/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.5352\n",
      "Epoch 6: loss improved from 0.68959 to 0.68879, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6888 - accuracy: 0.5352 - val_loss: 0.7003 - val_accuracy: 0.5000\n",
      "Epoch 7/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5412\n",
      "Epoch 7: loss did not improve from 0.68879\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6896 - accuracy: 0.5412 - val_loss: 0.7130 - val_accuracy: 0.4444\n",
      "Epoch 8/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.5424\n",
      "Epoch 8: loss improved from 0.68879 to 0.68784, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6878 - accuracy: 0.5424 - val_loss: 0.7141 - val_accuracy: 0.4444\n",
      "Epoch 9/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.5384\n",
      "Epoch 9: loss did not improve from 0.68784\n",
      "20/20 [==============================] - 92s 5s/step - loss: 0.6883 - accuracy: 0.5384 - val_loss: 0.7020 - val_accuracy: 0.5000\n",
      "Epoch 10/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.5412\n",
      "Epoch 10: loss improved from 0.68784 to 0.68693, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6869 - accuracy: 0.5412 - val_loss: 0.7067 - val_accuracy: 0.4444\n",
      "Epoch 11/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.5459\n",
      "Epoch 11: loss improved from 0.68693 to 0.68687, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 92s 5s/step - loss: 0.6869 - accuracy: 0.5459 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
      "Epoch 12/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.5546\n",
      "Epoch 12: loss did not improve from 0.68687\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.6884 - accuracy: 0.5546 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
      "Epoch 13/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.5527\n",
      "Epoch 13: loss improved from 0.68687 to 0.68627, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.6863 - accuracy: 0.5527 - val_loss: 0.7049 - val_accuracy: 0.5000\n",
      "Epoch 14/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5420\n",
      "Epoch 14: loss did not improve from 0.68627\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.6872 - accuracy: 0.5420 - val_loss: 0.7045 - val_accuracy: 0.5000\n",
      "Epoch 15/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5530\n",
      "Epoch 15: loss improved from 0.68627 to 0.68559, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6856 - accuracy: 0.5530 - val_loss: 0.7096 - val_accuracy: 0.5556\n",
      "Epoch 16/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.5463\n",
      "Epoch 16: loss improved from 0.68559 to 0.68446, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.6845 - accuracy: 0.5463 - val_loss: 0.7254 - val_accuracy: 0.4444\n",
      "Epoch 17/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5499\n",
      "Epoch 17: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6856 - accuracy: 0.5499 - val_loss: 0.7165 - val_accuracy: 0.4444\n",
      "Epoch 18/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.5542\n",
      "Epoch 18: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6866 - accuracy: 0.5542 - val_loss: 0.7013 - val_accuracy: 0.5000\n",
      "Epoch 19/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.5527\n",
      "Epoch 19: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.6852 - accuracy: 0.5527 - val_loss: 0.6916 - val_accuracy: 0.6111\n",
      "Epoch 20/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.5562\n",
      "Epoch 20: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6854 - accuracy: 0.5562 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 21/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5546\n",
      "Epoch 21: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6856 - accuracy: 0.5546 - val_loss: 0.6963 - val_accuracy: 0.5556\n",
      "Epoch 22/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.5471\n",
      "Epoch 22: loss did not improve from 0.68446\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6857 - accuracy: 0.5471 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 23/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5570\n",
      "Epoch 23: loss improved from 0.68446 to 0.68303, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 90s 5s/step - loss: 0.6830 - accuracy: 0.5570 - val_loss: 0.6815 - val_accuracy: 0.5556\n",
      "Epoch 24/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.5451\n",
      "Epoch 24: loss did not improve from 0.68303\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.6849 - accuracy: 0.5451 - val_loss: 0.7011 - val_accuracy: 0.5556\n",
      "Epoch 25/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.5598\n",
      "Epoch 25: loss improved from 0.68303 to 0.68257, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.6826 - accuracy: 0.5598 - val_loss: 0.6987 - val_accuracy: 0.5556\n",
      "Epoch 26/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.5491\n",
      "Epoch 26: loss did not improve from 0.68257\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6854 - accuracy: 0.5491 - val_loss: 0.6876 - val_accuracy: 0.5556\n",
      "Epoch 27/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5503\n",
      "Epoch 27: loss did not improve from 0.68257\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6830 - accuracy: 0.5503 - val_loss: 0.6973 - val_accuracy: 0.5556\n",
      "Epoch 28/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.5527\n",
      "Epoch 28: loss did not improve from 0.68257\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6827 - accuracy: 0.5527 - val_loss: 0.6781 - val_accuracy: 0.6111\n",
      "Epoch 29/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.5610\n",
      "Epoch 29: loss improved from 0.68257 to 0.68089, saving model to my_best_model_.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 86s 4s/step - loss: 0.6809 - accuracy: 0.5610 - val_loss: 0.6840 - val_accuracy: 0.6111\n",
      "Epoch 30/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.5523\n",
      "Epoch 30: loss did not improve from 0.68089\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6825 - accuracy: 0.5523 - val_loss: 0.6792 - val_accuracy: 0.6111\n",
      "Epoch 31/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.5570\n",
      "Epoch 31: loss improved from 0.68089 to 0.67767, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6777 - accuracy: 0.5570 - val_loss: 0.6679 - val_accuracy: 0.6111\n",
      "Epoch 32/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.5610\n",
      "Epoch 32: loss did not improve from 0.67767\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6789 - accuracy: 0.5610 - val_loss: 0.6667 - val_accuracy: 0.6111\n",
      "Epoch 33/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.5614\n",
      "Epoch 33: loss did not improve from 0.67767\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6800 - accuracy: 0.5614 - val_loss: 0.6774 - val_accuracy: 0.5556\n",
      "Epoch 34/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.5756\n",
      "Epoch 34: loss improved from 0.67767 to 0.67674, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.6767 - accuracy: 0.5756 - val_loss: 0.6621 - val_accuracy: 0.5556\n",
      "Epoch 35/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.5724\n",
      "Epoch 35: loss improved from 0.67674 to 0.67558, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.6756 - accuracy: 0.5724 - val_loss: 0.6149 - val_accuracy: 0.6667\n",
      "Epoch 36/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.5736\n",
      "Epoch 36: loss improved from 0.67558 to 0.67355, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6736 - accuracy: 0.5736 - val_loss: 0.6546 - val_accuracy: 0.6111\n",
      "Epoch 37/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.5752\n",
      "Epoch 37: loss improved from 0.67355 to 0.66947, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6695 - accuracy: 0.5752 - val_loss: 0.6664 - val_accuracy: 0.5556\n",
      "Epoch 38/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.5808\n",
      "Epoch 38: loss improved from 0.66947 to 0.66905, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6691 - accuracy: 0.5808 - val_loss: 0.6579 - val_accuracy: 0.5556\n",
      "Epoch 39/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.6057\n",
      "Epoch 39: loss improved from 0.66905 to 0.65976, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6598 - accuracy: 0.6057 - val_loss: 0.6790 - val_accuracy: 0.5556\n",
      "Epoch 40/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.5859\n",
      "Epoch 40: loss did not improve from 0.65976\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.6684 - accuracy: 0.5859 - val_loss: 0.6136 - val_accuracy: 0.6111\n",
      "Epoch 41/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.5808\n",
      "Epoch 41: loss did not improve from 0.65976\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6639 - accuracy: 0.5808 - val_loss: 0.7011 - val_accuracy: 0.5556\n",
      "Epoch 42/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.5867\n",
      "Epoch 42: loss did not improve from 0.65976\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.6605 - accuracy: 0.5867 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 43/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.6073\n",
      "Epoch 43: loss improved from 0.65976 to 0.64957, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.6496 - accuracy: 0.6073 - val_loss: 0.7293 - val_accuracy: 0.5000\n",
      "Epoch 44/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.6073\n",
      "Epoch 44: loss improved from 0.64957 to 0.64833, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.6483 - accuracy: 0.6073 - val_loss: 0.7084 - val_accuracy: 0.4444\n",
      "Epoch 45/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6515 - accuracy: 0.6105\n",
      "Epoch 45: loss did not improve from 0.64833\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6515 - accuracy: 0.6105 - val_loss: 0.7507 - val_accuracy: 0.4444\n",
      "Epoch 46/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.6255\n",
      "Epoch 46: loss improved from 0.64833 to 0.64004, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6400 - accuracy: 0.6255 - val_loss: 0.7700 - val_accuracy: 0.4444\n",
      "Epoch 47/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.6247\n",
      "Epoch 47: loss improved from 0.64004 to 0.63058, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6306 - accuracy: 0.6247 - val_loss: 0.7069 - val_accuracy: 0.5000\n",
      "Epoch 48/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.6291\n",
      "Epoch 48: loss improved from 0.63058 to 0.62600, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6260 - accuracy: 0.6291 - val_loss: 0.7555 - val_accuracy: 0.4444\n",
      "Epoch 49/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6330\n",
      "Epoch 49: loss improved from 0.62600 to 0.62172, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.6217 - accuracy: 0.6330 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 50/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6489\n",
      "Epoch 50: loss improved from 0.62172 to 0.60772, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6077 - accuracy: 0.6489 - val_loss: 0.7828 - val_accuracy: 0.5556\n",
      "Epoch 51/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.6524\n",
      "Epoch 51: loss improved from 0.60772 to 0.59979, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.5998 - accuracy: 0.6524 - val_loss: 0.7417 - val_accuracy: 0.5000\n",
      "Epoch 52/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.6706\n",
      "Epoch 52: loss improved from 0.59979 to 0.58710, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.5871 - accuracy: 0.6706 - val_loss: 0.8132 - val_accuracy: 0.6111\n",
      "Epoch 53/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.6770\n",
      "Epoch 53: loss improved from 0.58710 to 0.56969, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.5697 - accuracy: 0.6770 - val_loss: 0.9546 - val_accuracy: 0.5556\n",
      "Epoch 54/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.7035\n",
      "Epoch 54: loss improved from 0.56969 to 0.54927, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.5493 - accuracy: 0.7035 - val_loss: 0.7682 - val_accuracy: 0.5000\n",
      "Epoch 55/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.6968\n",
      "Epoch 55: loss improved from 0.54927 to 0.54245, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.5425 - accuracy: 0.6968 - val_loss: 0.9766 - val_accuracy: 0.5000\n",
      "Epoch 56/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.7047\n",
      "Epoch 56: loss improved from 0.54245 to 0.53251, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.5325 - accuracy: 0.7047 - val_loss: 0.9577 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7332\n",
      "Epoch 57: loss improved from 0.53251 to 0.50476, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.5048 - accuracy: 0.7332 - val_loss: 0.9342 - val_accuracy: 0.4444\n",
      "Epoch 58/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.7359\n",
      "Epoch 58: loss improved from 0.50476 to 0.49589, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.4959 - accuracy: 0.7359 - val_loss: 1.0560 - val_accuracy: 0.4444\n",
      "Epoch 59/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.7454\n",
      "Epoch 59: loss improved from 0.49589 to 0.47157, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.4716 - accuracy: 0.7454 - val_loss: 1.1916 - val_accuracy: 0.4444\n",
      "Epoch 60/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.7502\n",
      "Epoch 60: loss improved from 0.47157 to 0.46434, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.4643 - accuracy: 0.7502 - val_loss: 0.8223 - val_accuracy: 0.5556\n",
      "Epoch 61/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.7688\n",
      "Epoch 61: loss improved from 0.46434 to 0.44852, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.4485 - accuracy: 0.7688 - val_loss: 1.2632 - val_accuracy: 0.4444\n",
      "Epoch 62/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.7815\n",
      "Epoch 62: loss improved from 0.44852 to 0.42207, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.4221 - accuracy: 0.7815 - val_loss: 1.2964 - val_accuracy: 0.4444\n",
      "Epoch 63/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.8108\n",
      "Epoch 63: loss improved from 0.42207 to 0.39102, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.3910 - accuracy: 0.8108 - val_loss: 1.5674 - val_accuracy: 0.4444\n",
      "Epoch 64/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8151\n",
      "Epoch 64: loss improved from 0.39102 to 0.37362, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.3736 - accuracy: 0.8151 - val_loss: 1.5933 - val_accuracy: 0.5556\n",
      "Epoch 65/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8258\n",
      "Epoch 65: loss improved from 0.37362 to 0.34885, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.3488 - accuracy: 0.8258 - val_loss: 1.7734 - val_accuracy: 0.5000\n",
      "Epoch 66/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8266\n",
      "Epoch 66: loss did not improve from 0.34885\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.3490 - accuracy: 0.8266 - val_loss: 1.3066 - val_accuracy: 0.5556\n",
      "Epoch 67/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8389\n",
      "Epoch 67: loss improved from 0.34885 to 0.32718, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.3272 - accuracy: 0.8389 - val_loss: 1.4298 - val_accuracy: 0.5556\n",
      "Epoch 68/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.8658\n",
      "Epoch 68: loss improved from 0.32718 to 0.29021, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.2902 - accuracy: 0.8658 - val_loss: 1.6906 - val_accuracy: 0.5556\n",
      "Epoch 69/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.8903\n",
      "Epoch 69: loss improved from 0.29021 to 0.24494, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.2449 - accuracy: 0.8903 - val_loss: 2.1796 - val_accuracy: 0.5556\n",
      "Epoch 70/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.8895\n",
      "Epoch 70: loss did not improve from 0.24494\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.2465 - accuracy: 0.8895 - val_loss: 2.2304 - val_accuracy: 0.5556\n",
      "Epoch 71/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.8872\n",
      "Epoch 71: loss improved from 0.24494 to 0.24261, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.2426 - accuracy: 0.8872 - val_loss: 2.2570 - val_accuracy: 0.6111\n",
      "Epoch 72/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9010\n",
      "Epoch 72: loss improved from 0.24261 to 0.21354, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 91s 5s/step - loss: 0.2135 - accuracy: 0.9010 - val_loss: 2.0648 - val_accuracy: 0.5556\n",
      "Epoch 73/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.9117\n",
      "Epoch 73: loss improved from 0.21354 to 0.19441, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.1944 - accuracy: 0.9117 - val_loss: 2.9281 - val_accuracy: 0.5000\n",
      "Epoch 74/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9165\n",
      "Epoch 74: loss did not improve from 0.19441\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.1976 - accuracy: 0.9165 - val_loss: 1.9231 - val_accuracy: 0.6667\n",
      "Epoch 75/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9252\n",
      "Epoch 75: loss improved from 0.19441 to 0.18010, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.1801 - accuracy: 0.9252 - val_loss: 2.1675 - val_accuracy: 0.5556\n",
      "Epoch 76/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9196\n",
      "Epoch 76: loss improved from 0.18010 to 0.17593, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.1759 - accuracy: 0.9196 - val_loss: 2.7457 - val_accuracy: 0.6111\n",
      "Epoch 77/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9398\n",
      "Epoch 77: loss improved from 0.17593 to 0.15318, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.1532 - accuracy: 0.9398 - val_loss: 1.7025 - val_accuracy: 0.6111\n",
      "Epoch 78/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9390\n",
      "Epoch 78: loss improved from 0.15318 to 0.13548, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.1355 - accuracy: 0.9390 - val_loss: 1.8380 - val_accuracy: 0.6667\n",
      "Epoch 79/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9541\n",
      "Epoch 79: loss improved from 0.13548 to 0.12145, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.1214 - accuracy: 0.9541 - val_loss: 2.4255 - val_accuracy: 0.6111\n",
      "Epoch 80/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9470\n",
      "Epoch 80: loss improved from 0.12145 to 0.11959, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 93s 5s/step - loss: 0.1196 - accuracy: 0.9470 - val_loss: 2.9487 - val_accuracy: 0.6667\n",
      "Epoch 81/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9458\n",
      "Epoch 81: loss did not improve from 0.11959\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.1343 - accuracy: 0.9458 - val_loss: 2.1089 - val_accuracy: 0.6111\n",
      "Epoch 82/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9422\n",
      "Epoch 82: loss did not improve from 0.11959\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.1238 - accuracy: 0.9422 - val_loss: 2.4164 - val_accuracy: 0.6111\n",
      "Epoch 83/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9458\n",
      "Epoch 83: loss did not improve from 0.11959\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.1224 - accuracy: 0.9458 - val_loss: 2.5183 - val_accuracy: 0.6111\n",
      "Epoch 84/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9576\n",
      "Epoch 84: loss improved from 0.11959 to 0.10213, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.1021 - accuracy: 0.9576 - val_loss: 3.1677 - val_accuracy: 0.4444\n",
      "Epoch 85/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9671\n",
      "Epoch 85: loss improved from 0.10213 to 0.08218, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 91s 5s/step - loss: 0.0822 - accuracy: 0.9671 - val_loss: 2.6917 - val_accuracy: 0.5556\n",
      "Epoch 86/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9774\n",
      "Epoch 86: loss improved from 0.08218 to 0.05990, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 3.4288 - val_accuracy: 0.5556\n",
      "Epoch 87/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9778\n",
      "Epoch 87: loss improved from 0.05990 to 0.05948, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0595 - accuracy: 0.9778 - val_loss: 3.4756 - val_accuracy: 0.6111\n",
      "Epoch 88/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9762\n",
      "Epoch 88: loss improved from 0.05948 to 0.05868, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.0587 - accuracy: 0.9762 - val_loss: 3.6720 - val_accuracy: 0.6111\n",
      "Epoch 89/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9731\n",
      "Epoch 89: loss did not improve from 0.05868\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0651 - accuracy: 0.9731 - val_loss: 3.5677 - val_accuracy: 0.6111\n",
      "Epoch 90/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9743\n",
      "Epoch 90: loss did not improve from 0.05868\n",
      "20/20 [==============================] - 90s 4s/step - loss: 0.0783 - accuracy: 0.9743 - val_loss: 2.4937 - val_accuracy: 0.5556\n",
      "Epoch 91/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9671\n",
      "Epoch 91: loss did not improve from 0.05868\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.0820 - accuracy: 0.9671 - val_loss: 2.1118 - val_accuracy: 0.6667\n",
      "Epoch 92/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9759\n",
      "Epoch 92: loss improved from 0.05868 to 0.05660, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0566 - accuracy: 0.9759 - val_loss: 2.3914 - val_accuracy: 0.7222\n",
      "Epoch 93/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9850\n",
      "Epoch 93: loss improved from 0.05660 to 0.04672, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 3.0939 - val_accuracy: 0.6667\n",
      "Epoch 94/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9842\n",
      "Epoch 94: loss improved from 0.04672 to 0.04015, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.0402 - accuracy: 0.9842 - val_loss: 3.3683 - val_accuracy: 0.6667\n",
      "Epoch 95/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9885\n",
      "Epoch 95: loss improved from 0.04015 to 0.03543, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 3.8503 - val_accuracy: 0.6111\n",
      "Epoch 96/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9830\n",
      "Epoch 96: loss did not improve from 0.03543\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 3.2506 - val_accuracy: 0.6111\n",
      "Epoch 97/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9794\n",
      "Epoch 97: loss did not improve from 0.03543\n",
      "20/20 [==============================] - 90s 5s/step - loss: 0.0571 - accuracy: 0.9794 - val_loss: 4.0964 - val_accuracy: 0.6111\n",
      "Epoch 98/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9755\n",
      "Epoch 98: loss did not improve from 0.03543\n",
      "20/20 [==============================] - 91s 5s/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 3.8332 - val_accuracy: 0.5556\n",
      "Epoch 99/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9850\n",
      "Epoch 99: loss did not improve from 0.03543\n",
      "20/20 [==============================] - 89s 4s/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 3.3310 - val_accuracy: 0.6111\n",
      "Epoch 100/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9861\n",
      "Epoch 100: loss did not improve from 0.03543\n",
      "20/20 [==============================] - 90s 5s/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 3.6039 - val_accuracy: 0.6111\n",
      "Epoch 101/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9913\n",
      "Epoch 101: loss improved from 0.03543 to 0.03255, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 3.8347 - val_accuracy: 0.6111\n",
      "Epoch 102/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9905\n",
      "Epoch 102: loss improved from 0.03255 to 0.02587, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 2.7861 - val_accuracy: 0.6667\n",
      "Epoch 103/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9972\n",
      "Epoch 103: loss improved from 0.02587 to 0.01183, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 2.6028 - val_accuracy: 0.6667\n",
      "Epoch 104/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9980\n",
      "Epoch 104: loss improved from 0.01183 to 0.00951, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 2.2144 - val_accuracy: 0.6667\n",
      "Epoch 105/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9960\n",
      "Epoch 105: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 3.0386 - val_accuracy: 0.5556\n",
      "Epoch 106/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 106: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 4.2628 - val_accuracy: 0.5000\n",
      "Epoch 107/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 107: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 5.0971 - val_accuracy: 0.5556\n",
      "Epoch 108/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956\n",
      "Epoch 108: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 3.9569 - val_accuracy: 0.6111\n",
      "Epoch 109/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9941\n",
      "Epoch 109: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.0146 - accuracy: 0.9941 - val_loss: 4.1630 - val_accuracy: 0.5556\n",
      "Epoch 110/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9968\n",
      "Epoch 110: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 5.2302 - val_accuracy: 0.5556\n",
      "Epoch 111/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9960\n",
      "Epoch 111: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 5.2761 - val_accuracy: 0.5000\n",
      "Epoch 112/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9921\n",
      "Epoch 112: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 5.5436 - val_accuracy: 0.5556\n",
      "Epoch 113/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9909\n",
      "Epoch 113: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 4.8580 - val_accuracy: 0.5556\n",
      "Epoch 114/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9905\n",
      "Epoch 114: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0209 - accuracy: 0.9905 - val_loss: 4.7172 - val_accuracy: 0.5556\n",
      "Epoch 115/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 115: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 5.7209 - val_accuracy: 0.5556\n",
      "Epoch 116/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9956\n",
      "Epoch 116: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 5.0959 - val_accuracy: 0.5556\n",
      "Epoch 117/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 117: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 4.8770 - val_accuracy: 0.5556\n",
      "Epoch 118/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972\n",
      "Epoch 118: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 5.0628 - val_accuracy: 0.5556\n",
      "Epoch 119/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9956\n",
      "Epoch 119: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 5.3813 - val_accuracy: 0.5556\n",
      "Epoch 120/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9968\n",
      "Epoch 120: loss improved from 0.00951 to 0.00895, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 5.3464 - val_accuracy: 0.5556\n",
      "Epoch 121/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9941\n",
      "Epoch 121: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 5.1943 - val_accuracy: 0.6111\n",
      "Epoch 122/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9952\n",
      "Epoch 122: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 5.4690 - val_accuracy: 0.5556\n",
      "Epoch 123/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9929\n",
      "Epoch 123: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0172 - accuracy: 0.9929 - val_loss: 5.3862 - val_accuracy: 0.5556\n",
      "Epoch 124/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9937\n",
      "Epoch 124: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 5.4807 - val_accuracy: 0.5556\n",
      "Epoch 125/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9901\n",
      "Epoch 125: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0254 - accuracy: 0.9901 - val_loss: 5.2499 - val_accuracy: 0.5556\n",
      "Epoch 126/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9893\n",
      "Epoch 126: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 4.6080 - val_accuracy: 0.5000\n",
      "Epoch 127/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9952\n",
      "Epoch 127: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 4.1201 - val_accuracy: 0.6111\n",
      "Epoch 128/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 128: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 4.6962 - val_accuracy: 0.5556\n",
      "Epoch 129/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9968\n",
      "Epoch 129: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 5.4209 - val_accuracy: 0.5556\n",
      "Epoch 130/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9956\n",
      "Epoch 130: loss did not improve from 0.00895\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 4.8682 - val_accuracy: 0.5556\n",
      "Epoch 131/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 131: loss improved from 0.00895 to 0.00747, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 5.0226 - val_accuracy: 0.5556\n",
      "Epoch 132/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9976\n",
      "Epoch 132: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0170 - accuracy: 0.9976 - val_loss: 5.2573 - val_accuracy: 0.5556\n",
      "Epoch 133/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9960\n",
      "Epoch 133: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 4.2563 - val_accuracy: 0.6111\n",
      "Epoch 134/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 134: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 4.1613 - val_accuracy: 0.6111\n",
      "Epoch 135/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9964\n",
      "Epoch 135: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 4.7203 - val_accuracy: 0.6111\n",
      "Epoch 136/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 136: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 4.5506 - val_accuracy: 0.6111\n",
      "Epoch 137/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 137: loss did not improve from 0.00747\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 4.0412 - val_accuracy: 0.6111\n",
      "Epoch 138/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 138: loss improved from 0.00747 to 0.00489, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 3.8648 - val_accuracy: 0.6667\n",
      "Epoch 139/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9964\n",
      "Epoch 139: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 3.7029 - val_accuracy: 0.5556\n",
      "Epoch 140/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 140: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 2.9909 - val_accuracy: 0.6667\n",
      "Epoch 141/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9952\n",
      "Epoch 141: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 3.5449 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9921\n",
      "Epoch 142: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 4.2330 - val_accuracy: 0.5556\n",
      "Epoch 143/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 143: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 4.3750 - val_accuracy: 0.6667\n",
      "Epoch 144/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 144: loss did not improve from 0.00489\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 4.8983 - val_accuracy: 0.5556\n",
      "Epoch 145/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 145: loss improved from 0.00489 to 0.00397, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 5.4735 - val_accuracy: 0.5556\n",
      "Epoch 146/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 146: loss did not improve from 0.00397\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 5.8310 - val_accuracy: 0.5556\n",
      "Epoch 147/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 147: loss improved from 0.00397 to 0.00143, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.9620 - val_accuracy: 0.5556\n",
      "Epoch 148/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 148: loss did not improve from 0.00143\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 5.8858 - val_accuracy: 0.5556\n",
      "Epoch 149/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 149: loss improved from 0.00143 to 0.00101, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.0541 - val_accuracy: 0.5556\n",
      "Epoch 150/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.8995e-04 - accuracy: 1.0000\n",
      "Epoch 150: loss improved from 0.00101 to 0.00049, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 82s 4s/step - loss: 4.8995e-04 - accuracy: 1.0000 - val_loss: 6.1369 - val_accuracy: 0.5556\n",
      "Epoch 151/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.7894e-04 - accuracy: 0.9996\n",
      "Epoch 151: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 9.7894e-04 - accuracy: 0.9996 - val_loss: 5.8688 - val_accuracy: 0.5556\n",
      "Epoch 152/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 152: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 6.0480 - val_accuracy: 0.5556\n",
      "Epoch 153/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n",
      "Epoch 153: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 5.4934 - val_accuracy: 0.5556\n",
      "Epoch 154/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 154: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 5.0277 - val_accuracy: 0.6111\n",
      "Epoch 155/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9984\n",
      "Epoch 155: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 5.1582 - val_accuracy: 0.6111\n",
      "Epoch 156/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9980\n",
      "Epoch 156: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 5.0971 - val_accuracy: 0.6111\n",
      "Epoch 157/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9988\n",
      "Epoch 157: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 5.5055 - val_accuracy: 0.6111\n",
      "Epoch 158/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 158: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 5.0581 - val_accuracy: 0.6111\n",
      "Epoch 159/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9996\n",
      "Epoch 159: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 4.8797 - val_accuracy: 0.6111\n",
      "Epoch 160/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9992\n",
      "Epoch 160: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 5.0162 - val_accuracy: 0.5556\n",
      "Epoch 161/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9992\n",
      "Epoch 161: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 4.8507 - val_accuracy: 0.6111\n",
      "Epoch 162/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 162: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 4.7622 - val_accuracy: 0.6111\n",
      "Epoch 163/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 163: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 86s 4s/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 4.7833 - val_accuracy: 0.6111\n",
      "Epoch 164/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9968\n",
      "Epoch 164: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 5.2310 - val_accuracy: 0.6111\n",
      "Epoch 165/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9949\n",
      "Epoch 165: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 4.4586 - val_accuracy: 0.6667\n",
      "Epoch 166/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9941\n",
      "Epoch 166: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 4.4103 - val_accuracy: 0.5556\n",
      "Epoch 167/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9842\n",
      "Epoch 167: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 4.2460 - val_accuracy: 0.5000\n",
      "Epoch 168/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9846\n",
      "Epoch 168: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0620 - accuracy: 0.9846 - val_loss: 2.8103 - val_accuracy: 0.6667\n",
      "Epoch 169/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9881\n",
      "Epoch 169: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 3.1728 - val_accuracy: 0.6111\n",
      "Epoch 170/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9921\n",
      "Epoch 170: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 3.2273 - val_accuracy: 0.6111\n",
      "Epoch 171/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 171: loss did not improve from 0.00049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 82s 4s/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 2.6157 - val_accuracy: 0.6667\n",
      "Epoch 172/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9996\n",
      "Epoch 172: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 3.1773 - val_accuracy: 0.6111\n",
      "Epoch 173/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 173: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 3.3234 - val_accuracy: 0.6111\n",
      "Epoch 174/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 174: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 3.5325 - val_accuracy: 0.6111\n",
      "Epoch 175/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 175: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 3.9171 - val_accuracy: 0.6111\n",
      "Epoch 176/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9984\n",
      "Epoch 176: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 3.7530 - val_accuracy: 0.5556\n",
      "Epoch 177/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 177: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 3.8172 - val_accuracy: 0.6111\n",
      "Epoch 178/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9984\n",
      "Epoch 178: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 3.9278 - val_accuracy: 0.6667\n",
      "Epoch 179/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 179: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 4.0279 - val_accuracy: 0.5556\n",
      "Epoch 180/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 180: loss did not improve from 0.00049\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 4.3670 - val_accuracy: 0.6111\n",
      "Epoch 181/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.3026e-04 - accuracy: 1.0000\n",
      "Epoch 181: loss improved from 0.00049 to 0.00043, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 84s 4s/step - loss: 4.3026e-04 - accuracy: 1.0000 - val_loss: 4.3537 - val_accuracy: 0.6111\n",
      "Epoch 182/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9992\n",
      "Epoch 182: loss did not improve from 0.00043\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 4.2469 - val_accuracy: 0.6111\n",
      "Epoch 183/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.4466e-04 - accuracy: 1.0000\n",
      "Epoch 183: loss did not improve from 0.00043\n",
      "20/20 [==============================] - 83s 4s/step - loss: 7.4466e-04 - accuracy: 1.0000 - val_loss: 4.2682 - val_accuracy: 0.5556\n",
      "Epoch 184/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.6223e-04 - accuracy: 0.9996\n",
      "Epoch 184: loss did not improve from 0.00043\n",
      "20/20 [==============================] - 84s 4s/step - loss: 9.6223e-04 - accuracy: 0.9996 - val_loss: 4.3177 - val_accuracy: 0.5556\n",
      "Epoch 185/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.9869e-04 - accuracy: 1.0000\n",
      "Epoch 185: loss improved from 0.00043 to 0.00040, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 83s 4s/step - loss: 3.9869e-04 - accuracy: 1.0000 - val_loss: 4.3395 - val_accuracy: 0.6111\n",
      "Epoch 186/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.0842e-04 - accuracy: 0.9996\n",
      "Epoch 186: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 9.0842e-04 - accuracy: 0.9996 - val_loss: 4.2166 - val_accuracy: 0.6111\n",
      "Epoch 187/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 187: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 4.2316 - val_accuracy: 0.6111\n",
      "Epoch 188/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 188: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 5.3078 - val_accuracy: 0.6111\n",
      "Epoch 189/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9992\n",
      "Epoch 189: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0132 - accuracy: 0.9992 - val_loss: 5.3071 - val_accuracy: 0.6667\n",
      "Epoch 190/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9988\n",
      "Epoch 190: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 5.0000 - val_accuracy: 0.6667\n",
      "Epoch 191/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 191: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 4.4746 - val_accuracy: 0.6667\n",
      "Epoch 192/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9976\n",
      "Epoch 192: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 4.0838 - val_accuracy: 0.6667\n",
      "Epoch 193/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9949\n",
      "Epoch 193: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 4.0756 - val_accuracy: 0.5556\n",
      "Epoch 194/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9952\n",
      "Epoch 194: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 4.1066 - val_accuracy: 0.6111\n",
      "Epoch 195/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9952\n",
      "Epoch 195: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 3.6305 - val_accuracy: 0.6111\n",
      "Epoch 196/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9945\n",
      "Epoch 196: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 3.9957 - val_accuracy: 0.6111\n",
      "Epoch 197/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9893\n",
      "Epoch 197: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 3.7015 - val_accuracy: 0.6111\n",
      "Epoch 198/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9861\n",
      "Epoch 198: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 3.5313 - val_accuracy: 0.6111\n",
      "Epoch 199/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 199: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 3.9766 - val_accuracy: 0.5556\n",
      "Epoch 200/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9917\n",
      "Epoch 200: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 4.5541 - val_accuracy: 0.5000\n",
      "Epoch 201/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 201: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 3.8736 - val_accuracy: 0.5556\n",
      "Epoch 202/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9984\n",
      "Epoch 202: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 4.0569 - val_accuracy: 0.5000\n",
      "Epoch 203/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9964\n",
      "Epoch 203: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 4.3928 - val_accuracy: 0.5000\n",
      "Epoch 204/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 204: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 4.1523 - val_accuracy: 0.6111\n",
      "Epoch 205/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 205: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 4.6859 - val_accuracy: 0.5556\n",
      "Epoch 206/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 206: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 4.5724 - val_accuracy: 0.5556\n",
      "Epoch 207/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 207: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 4.5556 - val_accuracy: 0.5556\n",
      "Epoch 208/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 208: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 4.6231 - val_accuracy: 0.5556\n",
      "Epoch 209/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 209: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 4.8203 - val_accuracy: 0.5556\n",
      "Epoch 210/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 210: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 4.6626 - val_accuracy: 0.5556\n",
      "Epoch 211/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9956\n",
      "Epoch 211: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0094 - accuracy: 0.9956 - val_loss: 4.9909 - val_accuracy: 0.5000\n",
      "Epoch 212/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 212: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0163 - accuracy: 0.9941 - val_loss: 5.5680 - val_accuracy: 0.5000\n",
      "Epoch 213/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9956\n",
      "Epoch 213: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 5.9097 - val_accuracy: 0.4444\n",
      "Epoch 214/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9945\n",
      "Epoch 214: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 5.8920 - val_accuracy: 0.5556\n",
      "Epoch 215/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9996\n",
      "Epoch 215: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 5.9578 - val_accuracy: 0.5000\n",
      "Epoch 216/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9984\n",
      "Epoch 216: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 5.8852 - val_accuracy: 0.5000\n",
      "Epoch 217/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 217: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 5.5892 - val_accuracy: 0.5000\n",
      "Epoch 218/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 218: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 5.7203 - val_accuracy: 0.5556\n",
      "Epoch 219/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 219: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 5.8373 - val_accuracy: 0.5556\n",
      "Epoch 220/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9949\n",
      "Epoch 220: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 5.2770 - val_accuracy: 0.5556\n",
      "Epoch 221/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9913\n",
      "Epoch 221: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 4.7304 - val_accuracy: 0.5556\n",
      "Epoch 222/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9893\n",
      "Epoch 222: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 4.2313 - val_accuracy: 0.6111\n",
      "Epoch 223/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9842\n",
      "Epoch 223: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 2.8592 - val_accuracy: 0.6111\n",
      "Epoch 224/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949\n",
      "Epoch 224: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 3.9942 - val_accuracy: 0.6111\n",
      "Epoch 225/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 225: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 4.2795 - val_accuracy: 0.5556\n",
      "Epoch 226/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9996\n",
      "Epoch 226: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 4.4302 - val_accuracy: 0.5556\n",
      "Epoch 227/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 227: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 4.5539 - val_accuracy: 0.5556\n",
      "Epoch 228/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 228: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.6894 - val_accuracy: 0.5556\n",
      "Epoch 229/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.5315e-04 - accuracy: 1.0000\n",
      "Epoch 229: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 39s 2s/step - loss: 9.5315e-04 - accuracy: 1.0000 - val_loss: 4.7974 - val_accuracy: 0.5556\n",
      "Epoch 230/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.8578e-04 - accuracy: 1.0000\n",
      "Epoch 230: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 39s 2s/step - loss: 7.8578e-04 - accuracy: 1.0000 - val_loss: 4.9385 - val_accuracy: 0.5556\n",
      "Epoch 231/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 4.6960e-04 - accuracy: 1.0000\n",
      "Epoch 231: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 39s 2s/step - loss: 4.6960e-04 - accuracy: 1.0000 - val_loss: 5.0685 - val_accuracy: 0.5556\n",
      "Epoch 232/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.7181e-04 - accuracy: 1.0000\n",
      "Epoch 232: loss did not improve from 0.00040\n",
      "20/20 [==============================] - 39s 2s/step - loss: 5.7181e-04 - accuracy: 1.0000 - val_loss: 5.1699 - val_accuracy: 0.5556\n",
      "Epoch 233/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1936e-04 - accuracy: 1.0000\n",
      "Epoch 233: loss improved from 0.00040 to 0.00022, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 2.1936e-04 - accuracy: 1.0000 - val_loss: 5.3147 - val_accuracy: 0.5556\n",
      "Epoch 234/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 234: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 5.4648 - val_accuracy: 0.5556\n",
      "Epoch 235/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 235: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 5.3444 - val_accuracy: 0.5556\n",
      "Epoch 236/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.2063e-04 - accuracy: 1.0000\n",
      "Epoch 236: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.2063e-04 - accuracy: 1.0000 - val_loss: 5.3690 - val_accuracy: 0.5556\n",
      "Epoch 237/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
      "Epoch 237: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.3836 - val_accuracy: 0.5556\n",
      "Epoch 238/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.2447e-04 - accuracy: 1.0000\n",
      "Epoch 238: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.2447e-04 - accuracy: 1.0000 - val_loss: 5.4705 - val_accuracy: 0.5556\n",
      "Epoch 239/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.6787e-04 - accuracy: 0.9996\n",
      "Epoch 239: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.6787e-04 - accuracy: 0.9996 - val_loss: 5.5083 - val_accuracy: 0.5556\n",
      "Epoch 240/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 240: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 5.6088 - val_accuracy: 0.5556\n",
      "Epoch 241/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 241: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 5.1551 - val_accuracy: 0.5556\n",
      "Epoch 242/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 242: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 5.5096 - val_accuracy: 0.5556\n",
      "Epoch 243/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 243: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 5.5823 - val_accuracy: 0.5556\n",
      "Epoch 244/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9988\n",
      "Epoch 244: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0168 - accuracy: 0.9988 - val_loss: 5.0731 - val_accuracy: 0.5556\n",
      "Epoch 245/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9996\n",
      "Epoch 245: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 4.6478 - val_accuracy: 0.5556\n",
      "Epoch 246/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 246: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 4.8522 - val_accuracy: 0.5556\n",
      "Epoch 247/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9988\n",
      "Epoch 247: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 5.2181 - val_accuracy: 0.5000\n",
      "Epoch 248/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 248: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 4.9445 - val_accuracy: 0.5556\n",
      "Epoch 249/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9881\n",
      "Epoch 249: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 2.9925 - val_accuracy: 0.6667\n",
      "Epoch 250/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9794\n",
      "Epoch 250: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0752 - accuracy: 0.9794 - val_loss: 1.9702 - val_accuracy: 0.6667\n",
      "Epoch 251/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9873\n",
      "Epoch 251: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 2.2252 - val_accuracy: 0.7222\n",
      "Epoch 252/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9937\n",
      "Epoch 252: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 3.4618 - val_accuracy: 0.5556\n",
      "Epoch 253/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9976\n",
      "Epoch 253: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 4.5455 - val_accuracy: 0.5000\n",
      "Epoch 254/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 254: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 4.0443 - val_accuracy: 0.5000\n",
      "Epoch 255/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 255: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 4.2537 - val_accuracy: 0.5556\n",
      "Epoch 256/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 256: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4385 - val_accuracy: 0.5556\n",
      "Epoch 257/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 257: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.6290 - val_accuracy: 0.5556\n",
      "Epoch 258/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.8077e-04 - accuracy: 1.0000\n",
      "Epoch 258: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.8077e-04 - accuracy: 1.0000 - val_loss: 4.6797 - val_accuracy: 0.5556\n",
      "Epoch 259/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.2451e-04 - accuracy: 1.0000\n",
      "Epoch 259: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.2451e-04 - accuracy: 1.0000 - val_loss: 4.6878 - val_accuracy: 0.5556\n",
      "Epoch 260/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8822e-04 - accuracy: 1.0000\n",
      "Epoch 260: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8822e-04 - accuracy: 1.0000 - val_loss: 4.7434 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.0572e-04 - accuracy: 1.0000\n",
      "Epoch 261: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.0572e-04 - accuracy: 1.0000 - val_loss: 4.8070 - val_accuracy: 0.5556\n",
      "Epoch 262/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.7517e-04 - accuracy: 1.0000\n",
      "Epoch 262: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.7517e-04 - accuracy: 1.0000 - val_loss: 4.8442 - val_accuracy: 0.5556\n",
      "Epoch 263/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9988\n",
      "Epoch 263: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 4.8866 - val_accuracy: 0.6111\n",
      "Epoch 264/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 264: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 4.6664 - val_accuracy: 0.6111\n",
      "Epoch 265/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.7233e-04 - accuracy: 1.0000\n",
      "Epoch 265: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.7233e-04 - accuracy: 1.0000 - val_loss: 4.7994 - val_accuracy: 0.6111\n",
      "Epoch 266/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.4800e-04 - accuracy: 1.0000\n",
      "Epoch 266: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.4800e-04 - accuracy: 1.0000 - val_loss: 4.7817 - val_accuracy: 0.6111\n",
      "Epoch 267/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.2788e-04 - accuracy: 1.0000\n",
      "Epoch 267: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.2788e-04 - accuracy: 1.0000 - val_loss: 4.7360 - val_accuracy: 0.6111\n",
      "Epoch 268/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.6404e-04 - accuracy: 1.0000\n",
      "Epoch 268: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.6404e-04 - accuracy: 1.0000 - val_loss: 4.6080 - val_accuracy: 0.6111\n",
      "Epoch 269/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.4138e-04 - accuracy: 1.0000\n",
      "Epoch 269: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.4138e-04 - accuracy: 1.0000 - val_loss: 4.8744 - val_accuracy: 0.6111\n",
      "Epoch 270/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 270: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 4.8602 - val_accuracy: 0.5556\n",
      "Epoch 271/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.1769e-04 - accuracy: 1.0000\n",
      "Epoch 271: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.1769e-04 - accuracy: 1.0000 - val_loss: 4.9667 - val_accuracy: 0.6111\n",
      "Epoch 272/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.9478e-04 - accuracy: 1.0000\n",
      "Epoch 272: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.9478e-04 - accuracy: 1.0000 - val_loss: 5.0551 - val_accuracy: 0.6111\n",
      "Epoch 273/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.9001e-04 - accuracy: 1.0000\n",
      "Epoch 273: loss did not improve from 0.00022\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.9001e-04 - accuracy: 1.0000 - val_loss: 4.9648 - val_accuracy: 0.6111\n",
      "Epoch 274/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.8835e-04 - accuracy: 1.0000\n",
      "Epoch 274: loss improved from 0.00022 to 0.00019, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.8835e-04 - accuracy: 1.0000 - val_loss: 5.0514 - val_accuracy: 0.6111\n",
      "Epoch 275/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4080e-04 - accuracy: 1.0000\n",
      "Epoch 275: loss improved from 0.00019 to 0.00014, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.4080e-04 - accuracy: 1.0000 - val_loss: 5.1219 - val_accuracy: 0.6111\n",
      "Epoch 276/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.6043e-04 - accuracy: 1.0000\n",
      "Epoch 276: loss did not improve from 0.00014\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.6043e-04 - accuracy: 1.0000 - val_loss: 5.2659 - val_accuracy: 0.6111\n",
      "Epoch 277/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.7481e-04 - accuracy: 1.0000\n",
      "Epoch 277: loss did not improve from 0.00014\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.7481e-04 - accuracy: 1.0000 - val_loss: 5.3694 - val_accuracy: 0.6111\n",
      "Epoch 278/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1006e-04 - accuracy: 1.0000\n",
      "Epoch 278: loss improved from 0.00014 to 0.00011, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.1006e-04 - accuracy: 1.0000 - val_loss: 5.4436 - val_accuracy: 0.5556\n",
      "Epoch 279/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4515e-04 - accuracy: 1.0000\n",
      "Epoch 279: loss did not improve from 0.00011\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.4515e-04 - accuracy: 1.0000 - val_loss: 5.4765 - val_accuracy: 0.5556\n",
      "Epoch 280/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.4501e-04 - accuracy: 1.0000\n",
      "Epoch 280: loss did not improve from 0.00011\n",
      "20/20 [==============================] - 41s 2s/step - loss: 2.4501e-04 - accuracy: 1.0000 - val_loss: 5.4669 - val_accuracy: 0.5556\n",
      "Epoch 281/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.1109e-05 - accuracy: 1.0000\n",
      "Epoch 281: loss improved from 0.00011 to 0.00009, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.1109e-05 - accuracy: 1.0000 - val_loss: 5.4387 - val_accuracy: 0.6111\n",
      "Epoch 282/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.4134e-05 - accuracy: 1.0000\n",
      "Epoch 282: loss did not improve from 0.00009\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.4134e-05 - accuracy: 1.0000 - val_loss: 5.4378 - val_accuracy: 0.6111\n",
      "Epoch 283/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.3282e-04 - accuracy: 1.0000\n",
      "Epoch 283: loss did not improve from 0.00009\n",
      "20/20 [==============================] - 41s 2s/step - loss: 3.3282e-04 - accuracy: 1.0000 - val_loss: 5.5509 - val_accuracy: 0.5556\n",
      "Epoch 284/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4560e-04 - accuracy: 1.0000\n",
      "Epoch 284: loss did not improve from 0.00009\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.4560e-04 - accuracy: 1.0000 - val_loss: 5.5828 - val_accuracy: 0.5556\n",
      "Epoch 285/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.8336e-04 - accuracy: 1.0000\n",
      "Epoch 285: loss did not improve from 0.00009\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.8336e-04 - accuracy: 1.0000 - val_loss: 5.6482 - val_accuracy: 0.5556\n",
      "Epoch 286/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.3437e-05 - accuracy: 1.0000\n",
      "Epoch 286: loss improved from 0.00009 to 0.00008, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.3437e-05 - accuracy: 1.0000 - val_loss: 5.6980 - val_accuracy: 0.5556\n",
      "Epoch 287/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1872e-04 - accuracy: 1.0000\n",
      "Epoch 287: loss did not improve from 0.00008\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.1872e-04 - accuracy: 1.0000 - val_loss: 5.7213 - val_accuracy: 0.6111\n",
      "Epoch 288/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.5070e-05 - accuracy: 1.0000\n",
      "Epoch 288: loss improved from 0.00008 to 0.00008, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.5070e-05 - accuracy: 1.0000 - val_loss: 5.7310 - val_accuracy: 0.6111\n",
      "Epoch 289/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.6139e-05 - accuracy: 1.0000\n",
      "Epoch 289: loss did not improve from 0.00008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 40s 2s/step - loss: 8.6139e-05 - accuracy: 1.0000 - val_loss: 5.7582 - val_accuracy: 0.6111\n",
      "Epoch 290/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.2652e-05 - accuracy: 1.0000\n",
      "Epoch 290: loss improved from 0.00008 to 0.00007, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.2652e-05 - accuracy: 1.0000 - val_loss: 5.7719 - val_accuracy: 0.6111\n",
      "Epoch 291/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.7640e-05 - accuracy: 1.0000\n",
      "Epoch 291: loss improved from 0.00007 to 0.00005, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.7640e-05 - accuracy: 1.0000 - val_loss: 5.7819 - val_accuracy: 0.6111\n",
      "Epoch 292/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.6069e-05 - accuracy: 1.0000\n",
      "Epoch 292: loss did not improve from 0.00005\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.6069e-05 - accuracy: 1.0000 - val_loss: 5.8309 - val_accuracy: 0.6111\n",
      "Epoch 293/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.4743e-05 - accuracy: 1.0000\n",
      "Epoch 293: loss did not improve from 0.00005\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.4743e-05 - accuracy: 1.0000 - val_loss: 5.8396 - val_accuracy: 0.6111\n",
      "Epoch 294/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.5452e-05 - accuracy: 1.0000\n",
      "Epoch 294: loss improved from 0.00005 to 0.00003, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.5452e-05 - accuracy: 1.0000 - val_loss: 5.8421 - val_accuracy: 0.6111\n",
      "Epoch 295/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0941e-05 - accuracy: 1.0000\n",
      "Epoch 295: loss improved from 0.00003 to 0.00002, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0941e-05 - accuracy: 1.0000 - val_loss: 5.8507 - val_accuracy: 0.6111\n",
      "Epoch 296/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.2604e-05 - accuracy: 1.0000\n",
      "Epoch 296: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.2604e-05 - accuracy: 1.0000 - val_loss: 5.8487 - val_accuracy: 0.6111\n",
      "Epoch 297/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8964e-05 - accuracy: 1.0000\n",
      "Epoch 297: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8964e-05 - accuracy: 1.0000 - val_loss: 5.8550 - val_accuracy: 0.6111\n",
      "Epoch 298/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.3509e-05 - accuracy: 1.0000\n",
      "Epoch 298: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.3509e-05 - accuracy: 1.0000 - val_loss: 5.8659 - val_accuracy: 0.6111\n",
      "Epoch 299/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.4530e-05 - accuracy: 1.0000\n",
      "Epoch 299: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.4530e-05 - accuracy: 1.0000 - val_loss: 5.8876 - val_accuracy: 0.6111\n",
      "Epoch 300/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.3071e-05 - accuracy: 1.0000\n",
      "Epoch 300: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.3071e-05 - accuracy: 1.0000 - val_loss: 5.9100 - val_accuracy: 0.6111\n",
      "Epoch 301/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.3792e-05 - accuracy: 1.0000\n",
      "Epoch 301: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.3792e-05 - accuracy: 1.0000 - val_loss: 5.9313 - val_accuracy: 0.6111\n",
      "Epoch 302/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.5379e-05 - accuracy: 1.0000\n",
      "Epoch 302: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 41s 2s/step - loss: 2.5379e-05 - accuracy: 1.0000 - val_loss: 5.9527 - val_accuracy: 0.6111\n",
      "Epoch 303/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.7899e-05 - accuracy: 1.0000\n",
      "Epoch 303: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.7899e-05 - accuracy: 1.0000 - val_loss: 5.9617 - val_accuracy: 0.6111\n",
      "Epoch 304/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.5759e-05 - accuracy: 1.0000\n",
      "Epoch 304: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.5759e-05 - accuracy: 1.0000 - val_loss: 5.9579 - val_accuracy: 0.6111\n",
      "Epoch 305/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.8907e-05 - accuracy: 1.0000\n",
      "Epoch 305: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.8907e-05 - accuracy: 1.0000 - val_loss: 5.9693 - val_accuracy: 0.6111\n",
      "Epoch 306/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.5476e-05 - accuracy: 1.0000\n",
      "Epoch 306: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.5476e-05 - accuracy: 1.0000 - val_loss: 6.0463 - val_accuracy: 0.6111\n",
      "Epoch 307/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.5358e-05 - accuracy: 1.0000\n",
      "Epoch 307: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.5358e-05 - accuracy: 1.0000 - val_loss: 6.0679 - val_accuracy: 0.6111\n",
      "Epoch 308/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.6804e-05 - accuracy: 1.0000\n",
      "Epoch 308: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.6804e-05 - accuracy: 1.0000 - val_loss: 6.0859 - val_accuracy: 0.6111\n",
      "Epoch 309/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.0164e-05 - accuracy: 1.0000\n",
      "Epoch 309: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.0164e-05 - accuracy: 1.0000 - val_loss: 6.1223 - val_accuracy: 0.6111\n",
      "Epoch 310/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8953e-05 - accuracy: 1.0000\n",
      "Epoch 310: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8953e-05 - accuracy: 1.0000 - val_loss: 6.1582 - val_accuracy: 0.6111\n",
      "Epoch 311/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.3844e-05 - accuracy: 1.0000\n",
      "Epoch 311: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.3844e-05 - accuracy: 1.0000 - val_loss: 6.1953 - val_accuracy: 0.6111\n",
      "Epoch 312/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.8173e-05 - accuracy: 1.0000\n",
      "Epoch 312: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.8173e-05 - accuracy: 1.0000 - val_loss: 6.2104 - val_accuracy: 0.6111\n",
      "Epoch 313/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.1072e-05 - accuracy: 1.0000\n",
      "Epoch 313: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.1072e-05 - accuracy: 1.0000 - val_loss: 6.2019 - val_accuracy: 0.6111\n",
      "Epoch 314/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.5872e-05 - accuracy: 1.0000\n",
      "Epoch 314: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.5872e-05 - accuracy: 1.0000 - val_loss: 6.2379 - val_accuracy: 0.6111\n",
      "Epoch 315/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.3883e-05 - accuracy: 1.0000\n",
      "Epoch 315: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.3883e-05 - accuracy: 1.0000 - val_loss: 6.2493 - val_accuracy: 0.6111\n",
      "Epoch 316/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.3957e-05 - accuracy: 1.0000\n",
      "Epoch 316: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.3957e-05 - accuracy: 1.0000 - val_loss: 6.2536 - val_accuracy: 0.6111\n",
      "Epoch 317/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2924e-05 - accuracy: 1.0000\n",
      "Epoch 317: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.2924e-05 - accuracy: 1.0000 - val_loss: 6.2494 - val_accuracy: 0.6111\n",
      "Epoch 318/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 2.4148e-05 - accuracy: 1.0000\n",
      "Epoch 318: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.4148e-05 - accuracy: 1.0000 - val_loss: 6.2674 - val_accuracy: 0.6111\n",
      "Epoch 319/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.8364e-05 - accuracy: 1.0000\n",
      "Epoch 319: loss improved from 0.00002 to 0.00002, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.8364e-05 - accuracy: 1.0000 - val_loss: 6.2925 - val_accuracy: 0.6111\n",
      "Epoch 320/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0683e-05 - accuracy: 1.0000\n",
      "Epoch 320: loss did not improve from 0.00002\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0683e-05 - accuracy: 1.0000 - val_loss: 6.3178 - val_accuracy: 0.6111\n",
      "Epoch 321/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.7073e-05 - accuracy: 1.0000\n",
      "Epoch 321: loss improved from 0.00002 to 0.00002, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.7073e-05 - accuracy: 1.0000 - val_loss: 6.3276 - val_accuracy: 0.6111\n",
      "Epoch 322/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0035e-05 - accuracy: 1.0000\n",
      "Epoch 322: loss improved from 0.00002 to 0.00001, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0035e-05 - accuracy: 1.0000 - val_loss: 6.3332 - val_accuracy: 0.6111\n",
      "Epoch 323/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0150e-05 - accuracy: 1.0000\n",
      "Epoch 323: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0150e-05 - accuracy: 1.0000 - val_loss: 6.3380 - val_accuracy: 0.6111\n",
      "Epoch 324/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0904e-05 - accuracy: 1.0000\n",
      "Epoch 324: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0904e-05 - accuracy: 1.0000 - val_loss: 6.3565 - val_accuracy: 0.6111\n",
      "Epoch 325/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.2252e-05 - accuracy: 1.0000\n",
      "Epoch 325: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.2252e-05 - accuracy: 1.0000 - val_loss: 6.3793 - val_accuracy: 0.6111\n",
      "Epoch 326/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.1158e-05 - accuracy: 1.0000\n",
      "Epoch 326: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.1158e-05 - accuracy: 1.0000 - val_loss: 6.3943 - val_accuracy: 0.6111\n",
      "Epoch 327/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.7819e-05 - accuracy: 1.0000\n",
      "Epoch 327: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.7819e-05 - accuracy: 1.0000 - val_loss: 6.3370 - val_accuracy: 0.5556\n",
      "Epoch 328/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.4163e-05 - accuracy: 1.0000\n",
      "Epoch 328: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.4163e-05 - accuracy: 1.0000 - val_loss: 6.3427 - val_accuracy: 0.5556\n",
      "Epoch 329/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1995e-05 - accuracy: 1.0000\n",
      "Epoch 329: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.1995e-05 - accuracy: 1.0000 - val_loss: 6.3545 - val_accuracy: 0.5556\n",
      "Epoch 330/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1301e-05 - accuracy: 1.0000\n",
      "Epoch 330: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.1301e-05 - accuracy: 1.0000 - val_loss: 6.3638 - val_accuracy: 0.5556\n",
      "Epoch 331/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5588e-05 - accuracy: 1.0000\n",
      "Epoch 331: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.5588e-05 - accuracy: 1.0000 - val_loss: 6.3781 - val_accuracy: 0.5556\n",
      "Epoch 332/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.0929e-06 - accuracy: 1.0000\n",
      "Epoch 332: loss improved from 0.00001 to 0.00001, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 41s 2s/step - loss: 9.0929e-06 - accuracy: 1.0000 - val_loss: 6.3840 - val_accuracy: 0.5556\n",
      "Epoch 333/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0440e-05 - accuracy: 1.0000\n",
      "Epoch 333: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0440e-05 - accuracy: 1.0000 - val_loss: 6.3747 - val_accuracy: 0.5556\n",
      "Epoch 334/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3656e-05 - accuracy: 1.0000\n",
      "Epoch 334: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.3656e-05 - accuracy: 1.0000 - val_loss: 6.3847 - val_accuracy: 0.5556\n",
      "Epoch 335/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.1718e-05 - accuracy: 1.0000\n",
      "Epoch 335: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.1718e-05 - accuracy: 1.0000 - val_loss: 6.4188 - val_accuracy: 0.5556\n",
      "Epoch 336/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0124e-05 - accuracy: 1.0000\n",
      "Epoch 336: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0124e-05 - accuracy: 1.0000 - val_loss: 6.4180 - val_accuracy: 0.5556\n",
      "Epoch 337/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.8264e-05 - accuracy: 1.0000\n",
      "Epoch 337: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 41s 2s/step - loss: 1.8264e-05 - accuracy: 1.0000 - val_loss: 6.4291 - val_accuracy: 0.5556\n",
      "Epoch 338/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8301e-05 - accuracy: 1.0000\n",
      "Epoch 338: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8301e-05 - accuracy: 1.0000 - val_loss: 6.4150 - val_accuracy: 0.5556\n",
      "Epoch 339/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1568e-05 - accuracy: 1.0000\n",
      "Epoch 339: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.1568e-05 - accuracy: 1.0000 - val_loss: 6.4235 - val_accuracy: 0.5556\n",
      "Epoch 340/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.6454e-06 - accuracy: 1.0000\n",
      "Epoch 340: loss improved from 0.00001 to 0.00001, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.6454e-06 - accuracy: 1.0000 - val_loss: 6.4294 - val_accuracy: 0.5556\n",
      "Epoch 341/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1580e-05 - accuracy: 1.0000\n",
      "Epoch 341: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.1580e-05 - accuracy: 1.0000 - val_loss: 6.4271 - val_accuracy: 0.5556\n",
      "Epoch 342/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.0047e-06 - accuracy: 1.0000\n",
      "Epoch 342: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.0047e-06 - accuracy: 1.0000 - val_loss: 6.4236 - val_accuracy: 0.5556\n",
      "Epoch 343/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.7277e-06 - accuracy: 1.0000\n",
      "Epoch 343: loss improved from 0.00001 to 0.00001, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.7277e-06 - accuracy: 1.0000 - val_loss: 6.4303 - val_accuracy: 0.5556\n",
      "Epoch 344/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1621e-05 - accuracy: 1.0000\n",
      "Epoch 344: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.1621e-05 - accuracy: 1.0000 - val_loss: 6.4339 - val_accuracy: 0.5556\n",
      "Epoch 345/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.9307e-06 - accuracy: 1.0000\n",
      "Epoch 345: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.9307e-06 - accuracy: 1.0000 - val_loss: 6.4362 - val_accuracy: 0.5556\n",
      "Epoch 346/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.9778e-06 - accuracy: 1.0000\n",
      "Epoch 346: loss did not improve from 0.00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 40s 2s/step - loss: 9.9778e-06 - accuracy: 1.0000 - val_loss: 6.4480 - val_accuracy: 0.5556\n",
      "Epoch 347/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.6178e-06 - accuracy: 1.0000\n",
      "Epoch 347: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.6178e-06 - accuracy: 1.0000 - val_loss: 6.4588 - val_accuracy: 0.5556\n",
      "Epoch 348/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5314e-05 - accuracy: 1.0000\n",
      "Epoch 348: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.5314e-05 - accuracy: 1.0000 - val_loss: 6.4558 - val_accuracy: 0.5556\n",
      "Epoch 349/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.0244e-06 - accuracy: 1.0000\n",
      "Epoch 349: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.0244e-06 - accuracy: 1.0000 - val_loss: 6.4562 - val_accuracy: 0.5556\n",
      "Epoch 350/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1843e-05 - accuracy: 1.0000\n",
      "Epoch 350: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.1843e-05 - accuracy: 1.0000 - val_loss: 6.4582 - val_accuracy: 0.5556\n",
      "Epoch 351/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.4543e-06 - accuracy: 1.0000\n",
      "Epoch 351: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.4543e-06 - accuracy: 1.0000 - val_loss: 6.4445 - val_accuracy: 0.5556\n",
      "Epoch 352/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.8441e-06 - accuracy: 1.0000\n",
      "Epoch 352: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.8441e-06 - accuracy: 1.0000 - val_loss: 6.4462 - val_accuracy: 0.5556\n",
      "Epoch 353/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.9172e-05 - accuracy: 1.0000\n",
      "Epoch 353: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.9172e-05 - accuracy: 1.0000 - val_loss: 6.4551 - val_accuracy: 0.5556\n",
      "Epoch 354/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4066e-05 - accuracy: 1.0000\n",
      "Epoch 354: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.4066e-05 - accuracy: 1.0000 - val_loss: 6.4806 - val_accuracy: 0.5556\n",
      "Epoch 355/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.3387e-06 - accuracy: 1.0000\n",
      "Epoch 355: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.3387e-06 - accuracy: 1.0000 - val_loss: 6.4904 - val_accuracy: 0.5556\n",
      "Epoch 356/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.4931e-06 - accuracy: 1.0000\n",
      "Epoch 356: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.4931e-06 - accuracy: 1.0000 - val_loss: 6.5008 - val_accuracy: 0.5556\n",
      "Epoch 357/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.8366e-06 - accuracy: 1.0000\n",
      "Epoch 357: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.8366e-06 - accuracy: 1.0000 - val_loss: 6.5128 - val_accuracy: 0.5556\n",
      "Epoch 358/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.2601e-05 - accuracy: 1.0000\n",
      "Epoch 358: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.2601e-05 - accuracy: 1.0000 - val_loss: 6.5145 - val_accuracy: 0.5556\n",
      "Epoch 359/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5794e-05 - accuracy: 1.0000\n",
      "Epoch 359: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.5794e-05 - accuracy: 1.0000 - val_loss: 6.5397 - val_accuracy: 0.5556\n",
      "Epoch 360/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.0699e-06 - accuracy: 1.0000\n",
      "Epoch 360: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.0699e-06 - accuracy: 1.0000 - val_loss: 6.5565 - val_accuracy: 0.5556\n",
      "Epoch 361/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.9939e-06 - accuracy: 1.0000\n",
      "Epoch 361: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.9939e-06 - accuracy: 1.0000 - val_loss: 6.5728 - val_accuracy: 0.5556\n",
      "Epoch 362/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.7763e-05 - accuracy: 1.0000\n",
      "Epoch 362: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.7763e-05 - accuracy: 1.0000 - val_loss: 6.5899 - val_accuracy: 0.5556\n",
      "Epoch 363/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.8836e-06 - accuracy: 1.0000\n",
      "Epoch 363: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.8836e-06 - accuracy: 1.0000 - val_loss: 6.5972 - val_accuracy: 0.5556\n",
      "Epoch 364/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.2197e-06 - accuracy: 1.0000\n",
      "Epoch 364: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.2197e-06 - accuracy: 1.0000 - val_loss: 6.6063 - val_accuracy: 0.5556\n",
      "Epoch 365/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.6097e-06 - accuracy: 1.0000\n",
      "Epoch 365: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.6097e-06 - accuracy: 1.0000 - val_loss: 6.6121 - val_accuracy: 0.5556\n",
      "Epoch 366/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.9692e-06 - accuracy: 1.0000\n",
      "Epoch 366: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.9692e-06 - accuracy: 1.0000 - val_loss: 6.6176 - val_accuracy: 0.5556\n",
      "Epoch 367/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0426e-05 - accuracy: 1.0000\n",
      "Epoch 367: loss did not improve from 0.00001\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0426e-05 - accuracy: 1.0000 - val_loss: 6.6187 - val_accuracy: 0.5556\n",
      "Epoch 368/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.7097e-06 - accuracy: 1.0000\n",
      "Epoch 368: loss improved from 0.00001 to 0.00000, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.7097e-06 - accuracy: 1.0000 - val_loss: 6.6262 - val_accuracy: 0.5556\n",
      "Epoch 369/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.6365e-05 - accuracy: 1.0000\n",
      "Epoch 369: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 41s 2s/step - loss: 1.6365e-05 - accuracy: 1.0000 - val_loss: 6.6359 - val_accuracy: 0.5556\n",
      "Epoch 370/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.0786e-06 - accuracy: 1.0000\n",
      "Epoch 370: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.0786e-06 - accuracy: 1.0000 - val_loss: 6.6421 - val_accuracy: 0.5556\n",
      "Epoch 371/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.0671e-06 - accuracy: 1.0000\n",
      "Epoch 371: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.0671e-06 - accuracy: 1.0000 - val_loss: 6.6506 - val_accuracy: 0.5556\n",
      "Epoch 372/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.2199e-06 - accuracy: 1.0000\n",
      "Epoch 372: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.2199e-06 - accuracy: 1.0000 - val_loss: 6.6609 - val_accuracy: 0.5556\n",
      "Epoch 373/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.3529e-06 - accuracy: 1.0000\n",
      "Epoch 373: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.3529e-06 - accuracy: 1.0000 - val_loss: 6.6700 - val_accuracy: 0.5556\n",
      "Epoch 374/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.5856e-06 - accuracy: 1.0000\n",
      "Epoch 374: loss improved from 0.00000 to 0.00000, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.5856e-06 - accuracy: 1.0000 - val_loss: 6.6780 - val_accuracy: 0.5556\n",
      "Epoch 375/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.5005e-06 - accuracy: 1.0000\n",
      "Epoch 375: loss did not improve from 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 41s 2s/step - loss: 9.5005e-06 - accuracy: 1.0000 - val_loss: 6.6784 - val_accuracy: 0.5556\n",
      "Epoch 376/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.9006e-06 - accuracy: 1.0000\n",
      "Epoch 376: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.9006e-06 - accuracy: 1.0000 - val_loss: 6.6883 - val_accuracy: 0.5556\n",
      "Epoch 377/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.8582e-06 - accuracy: 1.0000\n",
      "Epoch 377: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.8582e-06 - accuracy: 1.0000 - val_loss: 6.6948 - val_accuracy: 0.5556\n",
      "Epoch 378/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0310e-05 - accuracy: 1.0000\n",
      "Epoch 378: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0310e-05 - accuracy: 1.0000 - val_loss: 6.7145 - val_accuracy: 0.5556\n",
      "Epoch 379/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1216e-05 - accuracy: 1.0000\n",
      "Epoch 379: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.1216e-05 - accuracy: 1.0000 - val_loss: 6.7192 - val_accuracy: 0.5556\n",
      "Epoch 380/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.2925e-06 - accuracy: 1.0000\n",
      "Epoch 380: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.2925e-06 - accuracy: 1.0000 - val_loss: 6.7333 - val_accuracy: 0.5556\n",
      "Epoch 381/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.8630e-06 - accuracy: 1.0000\n",
      "Epoch 381: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.8630e-06 - accuracy: 1.0000 - val_loss: 6.7356 - val_accuracy: 0.5556\n",
      "Epoch 382/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.7562e-06 - accuracy: 1.0000\n",
      "Epoch 382: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.7562e-06 - accuracy: 1.0000 - val_loss: 6.7375 - val_accuracy: 0.5556\n",
      "Epoch 383/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.4306e-06 - accuracy: 1.0000\n",
      "Epoch 383: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.4306e-06 - accuracy: 1.0000 - val_loss: 6.7445 - val_accuracy: 0.5556\n",
      "Epoch 384/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8376e-06 - accuracy: 1.0000\n",
      "Epoch 384: loss improved from 0.00000 to 0.00000, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8376e-06 - accuracy: 1.0000 - val_loss: 6.7485 - val_accuracy: 0.5556\n",
      "Epoch 385/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.5993e-06 - accuracy: 1.0000\n",
      "Epoch 385: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.5993e-06 - accuracy: 1.0000 - val_loss: 6.7509 - val_accuracy: 0.5556\n",
      "Epoch 386/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5495e-05 - accuracy: 1.0000\n",
      "Epoch 386: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.5495e-05 - accuracy: 1.0000 - val_loss: 6.7845 - val_accuracy: 0.5556\n",
      "Epoch 387/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.2136e-06 - accuracy: 1.0000\n",
      "Epoch 387: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.2136e-06 - accuracy: 1.0000 - val_loss: 6.7995 - val_accuracy: 0.5556\n",
      "Epoch 388/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.0771e-06 - accuracy: 1.0000\n",
      "Epoch 388: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.0771e-06 - accuracy: 1.0000 - val_loss: 6.8010 - val_accuracy: 0.5556\n",
      "Epoch 389/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.4532e-06 - accuracy: 1.0000\n",
      "Epoch 389: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.4532e-06 - accuracy: 1.0000 - val_loss: 6.8048 - val_accuracy: 0.5556\n",
      "Epoch 390/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.5450e-06 - accuracy: 1.0000\n",
      "Epoch 390: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.5450e-06 - accuracy: 1.0000 - val_loss: 6.8071 - val_accuracy: 0.5556\n",
      "Epoch 391/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.9769e-06 - accuracy: 1.0000\n",
      "Epoch 391: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.9769e-06 - accuracy: 1.0000 - val_loss: 6.8161 - val_accuracy: 0.5556\n",
      "Epoch 392/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0421e-05 - accuracy: 1.0000\n",
      "Epoch 392: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0421e-05 - accuracy: 1.0000 - val_loss: 6.8113 - val_accuracy: 0.5556\n",
      "Epoch 393/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.1147e-06 - accuracy: 1.0000\n",
      "Epoch 393: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.1147e-06 - accuracy: 1.0000 - val_loss: 6.8114 - val_accuracy: 0.5556\n",
      "Epoch 394/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.2936e-06 - accuracy: 1.0000\n",
      "Epoch 394: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.2936e-06 - accuracy: 1.0000 - val_loss: 6.8147 - val_accuracy: 0.5556\n",
      "Epoch 395/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.8230e-06 - accuracy: 1.0000\n",
      "Epoch 395: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.8230e-06 - accuracy: 1.0000 - val_loss: 6.8117 - val_accuracy: 0.5556\n",
      "Epoch 396/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.7809e-05 - accuracy: 1.0000\n",
      "Epoch 396: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.7809e-05 - accuracy: 1.0000 - val_loss: 6.8616 - val_accuracy: 0.5556\n",
      "Epoch 397/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.5074e-06 - accuracy: 1.0000\n",
      "Epoch 397: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.5074e-06 - accuracy: 1.0000 - val_loss: 6.8805 - val_accuracy: 0.5556\n",
      "Epoch 398/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.6169e-06 - accuracy: 1.0000\n",
      "Epoch 398: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.6169e-06 - accuracy: 1.0000 - val_loss: 6.8844 - val_accuracy: 0.5556\n",
      "Epoch 399/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.5635e-06 - accuracy: 1.0000\n",
      "Epoch 399: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.5635e-06 - accuracy: 1.0000 - val_loss: 6.8774 - val_accuracy: 0.5556\n",
      "Epoch 400/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.9160e-06 - accuracy: 1.0000\n",
      "Epoch 400: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.9160e-06 - accuracy: 1.0000 - val_loss: 6.8776 - val_accuracy: 0.5556\n",
      "Epoch 401/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.2119e-06 - accuracy: 1.0000\n",
      "Epoch 401: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.2119e-06 - accuracy: 1.0000 - val_loss: 6.8928 - val_accuracy: 0.5556\n",
      "Epoch 402/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.5093e-06 - accuracy: 1.0000\n",
      "Epoch 402: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.5093e-06 - accuracy: 1.0000 - val_loss: 6.8965 - val_accuracy: 0.5556\n",
      "Epoch 403/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.8150e-06 - accuracy: 1.0000\n",
      "Epoch 403: loss improved from 0.00000 to 0.00000, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.8150e-06 - accuracy: 1.0000 - val_loss: 6.9004 - val_accuracy: 0.5556\n",
      "Epoch 404/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.0065e-06 - accuracy: 1.0000\n",
      "Epoch 404: loss did not improve from 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 40s 2s/step - loss: 3.0065e-06 - accuracy: 1.0000 - val_loss: 6.9038 - val_accuracy: 0.5556\n",
      "Epoch 405/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0144e-05 - accuracy: 1.0000\n",
      "Epoch 405: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0144e-05 - accuracy: 1.0000 - val_loss: 6.9034 - val_accuracy: 0.5556\n",
      "Epoch 406/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0451e-05 - accuracy: 1.0000\n",
      "Epoch 406: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0451e-05 - accuracy: 1.0000 - val_loss: 6.8683 - val_accuracy: 0.5556\n",
      "Epoch 407/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0327e-05 - accuracy: 1.0000\n",
      "Epoch 407: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 1.0327e-05 - accuracy: 1.0000 - val_loss: 6.8776 - val_accuracy: 0.5556\n",
      "Epoch 408/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0788e-06 - accuracy: 1.0000\n",
      "Epoch 408: loss improved from 0.00000 to 0.00000, saving model to my_best_model_.hdf5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.0788e-06 - accuracy: 1.0000 - val_loss: 6.8969 - val_accuracy: 0.5556\n",
      "Epoch 409/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.7431e-06 - accuracy: 1.0000\n",
      "Epoch 409: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.7431e-06 - accuracy: 1.0000 - val_loss: 6.9047 - val_accuracy: 0.5556\n",
      "Epoch 410/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.1304e-06 - accuracy: 1.0000\n",
      "Epoch 410: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.1304e-06 - accuracy: 1.0000 - val_loss: 6.9095 - val_accuracy: 0.5556\n",
      "Epoch 411/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.6817e-06 - accuracy: 1.0000\n",
      "Epoch 411: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.6817e-06 - accuracy: 1.0000 - val_loss: 6.9228 - val_accuracy: 0.5556\n",
      "Epoch 412/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.4127e-05 - accuracy: 1.0000\n",
      "Epoch 412: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.4127e-05 - accuracy: 1.0000 - val_loss: 6.9645 - val_accuracy: 0.5556\n",
      "Epoch 413/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.7543e-06 - accuracy: 1.0000\n",
      "Epoch 413: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 8.7543e-06 - accuracy: 1.0000 - val_loss: 6.9664 - val_accuracy: 0.5556\n",
      "Epoch 414/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.7502e-06 - accuracy: 1.0000\n",
      "Epoch 414: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.7502e-06 - accuracy: 1.0000 - val_loss: 6.9843 - val_accuracy: 0.5556\n",
      "Epoch 415/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.9923e-06 - accuracy: 1.0000\n",
      "Epoch 415: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.9923e-06 - accuracy: 1.0000 - val_loss: 6.9947 - val_accuracy: 0.5556\n",
      "Epoch 416/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.7235e-06 - accuracy: 1.0000\n",
      "Epoch 416: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.7235e-06 - accuracy: 1.0000 - val_loss: 7.0036 - val_accuracy: 0.5556\n",
      "Epoch 417/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.3797e-05 - accuracy: 1.0000\n",
      "Epoch 417: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.3797e-05 - accuracy: 1.0000 - val_loss: 7.0485 - val_accuracy: 0.5556\n",
      "Epoch 418/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9945\n",
      "Epoch 418: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0314 - accuracy: 0.9945 - val_loss: 5.1285 - val_accuracy: 0.6111\n",
      "Epoch 419/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8638\n",
      "Epoch 419: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.4057 - accuracy: 0.8638 - val_loss: 0.9000 - val_accuracy: 0.5000\n",
      "Epoch 420/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9113\n",
      "Epoch 420: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2218 - accuracy: 0.9113 - val_loss: 1.5330 - val_accuracy: 0.5000\n",
      "Epoch 421/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9596\n",
      "Epoch 421: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.1014 - accuracy: 0.9596 - val_loss: 1.7568 - val_accuracy: 0.5556\n",
      "Epoch 422/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9802\n",
      "Epoch 422: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0509 - accuracy: 0.9802 - val_loss: 1.9624 - val_accuracy: 0.6111\n",
      "Epoch 423/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9905\n",
      "Epoch 423: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 2.1138 - val_accuracy: 0.5556\n",
      "Epoch 424/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9968\n",
      "Epoch 424: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 3.0620 - val_accuracy: 0.5556\n",
      "Epoch 425/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9968\n",
      "Epoch 425: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 3.0056 - val_accuracy: 0.5556\n",
      "Epoch 426/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9964\n",
      "Epoch 426: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 2.8521 - val_accuracy: 0.6111\n",
      "Epoch 427/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9988\n",
      "Epoch 427: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 3.0975 - val_accuracy: 0.5556\n",
      "Epoch 428/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9976\n",
      "Epoch 428: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 3.8461 - val_accuracy: 0.6111\n",
      "Epoch 429/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 429: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 3.9677 - val_accuracy: 0.6111\n",
      "Epoch 430/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9968\n",
      "Epoch 430: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 4.0736 - val_accuracy: 0.6111\n",
      "Epoch 431/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984\n",
      "Epoch 431: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 4.0943 - val_accuracy: 0.6111\n",
      "Epoch 432/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 432: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 4.3140 - val_accuracy: 0.5556\n",
      "Epoch 433/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984\n",
      "Epoch 433: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 4.5140 - val_accuracy: 0.5000\n",
      "Epoch 434/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9941\n",
      "Epoch 434: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 3.9325 - val_accuracy: 0.5556\n",
      "Epoch 435/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 435: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 3.4324 - val_accuracy: 0.5556\n",
      "Epoch 436/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 436: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 4.0196 - val_accuracy: 0.5000\n",
      "Epoch 437/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9956\n",
      "Epoch 437: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 3.8288 - val_accuracy: 0.5556\n",
      "Epoch 438/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9964\n",
      "Epoch 438: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 4.0499 - val_accuracy: 0.5556\n",
      "Epoch 439/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 439: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 3.8630 - val_accuracy: 0.5556\n",
      "Epoch 440/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9960\n",
      "Epoch 440: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 3.7616 - val_accuracy: 0.5556\n",
      "Epoch 441/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9972\n",
      "Epoch 441: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 4.0137 - val_accuracy: 0.5556\n",
      "Epoch 442/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 442: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 4.2346 - val_accuracy: 0.5000\n",
      "Epoch 443/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9964\n",
      "Epoch 443: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 4.1767 - val_accuracy: 0.5000\n",
      "Epoch 444/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9956\n",
      "Epoch 444: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 4.5808 - val_accuracy: 0.5000\n",
      "Epoch 445/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9972\n",
      "Epoch 445: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 4.3760 - val_accuracy: 0.5556\n",
      "Epoch 446/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9956\n",
      "Epoch 446: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 3.9249 - val_accuracy: 0.5556\n",
      "Epoch 447/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 447: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 3.9722 - val_accuracy: 0.5556\n",
      "Epoch 448/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 448: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 4.4106 - val_accuracy: 0.6111\n",
      "Epoch 449/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 449: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.0200 - val_accuracy: 0.6111\n",
      "Epoch 450/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 9.2382e-04 - accuracy: 1.0000\n",
      "Epoch 450: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 9.2382e-04 - accuracy: 1.0000 - val_loss: 5.1161 - val_accuracy: 0.6111\n",
      "Epoch 451/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 7.7459e-04 - accuracy: 1.0000\n",
      "Epoch 451: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 7.7459e-04 - accuracy: 1.0000 - val_loss: 5.1830 - val_accuracy: 0.6111\n",
      "Epoch 452/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 452: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.4676 - val_accuracy: 0.5556\n",
      "Epoch 453/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 5.6544e-04 - accuracy: 1.0000\n",
      "Epoch 453: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 5.6544e-04 - accuracy: 1.0000 - val_loss: 5.5380 - val_accuracy: 0.5556\n",
      "Epoch 454/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.6892e-04 - accuracy: 1.0000\n",
      "Epoch 454: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.6892e-04 - accuracy: 1.0000 - val_loss: 5.4470 - val_accuracy: 0.6111\n",
      "Epoch 455/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.3680e-04 - accuracy: 1.0000\n",
      "Epoch 455: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.3680e-04 - accuracy: 1.0000 - val_loss: 5.3820 - val_accuracy: 0.6111\n",
      "Epoch 456/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 6.5828e-04 - accuracy: 0.9996\n",
      "Epoch 456: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.5828e-04 - accuracy: 0.9996 - val_loss: 5.4826 - val_accuracy: 0.6111\n",
      "Epoch 457/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.4941e-04 - accuracy: 1.0000\n",
      "Epoch 457: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 2.4941e-04 - accuracy: 1.0000 - val_loss: 5.5805 - val_accuracy: 0.6111\n",
      "Epoch 458/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.3954e-04 - accuracy: 1.0000\n",
      "Epoch 458: loss did not improve from 0.00000\n",
      "20/20 [==============================] - 40s 2s/step - loss: 3.3954e-04 - accuracy: 1.0000 - val_loss: 5.6094 - val_accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5000, batch_size=128, shuffle=True,\n",
    "                    validation_data=(X_test,y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ef7aa9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:46.325426Z",
     "iopub.status.busy": "2021-11-09T08:24:46.324389Z",
     "iopub.status.idle": "2021-11-09T08:24:46.568908Z",
     "shell.execute_reply": "2021-11-09T08:24:46.569365Z",
     "shell.execute_reply.started": "2021-11-09T07:54:23.288972Z"
    },
    "id": "75ef7aa9",
    "outputId": "7f914584-d0c3-4305-c3a1-8772a515cfe9",
    "papermill": {
     "duration": 0.46139,
     "end_time": "2021-11-09T08:24:46.569557",
     "exception": false,
     "start_time": "2021-11-09T08:24:46.108167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b511a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:35.370435Z",
     "iopub.status.busy": "2021-11-09T08:24:35.369774Z",
     "iopub.status.idle": "2021-11-09T08:24:45.892279Z",
     "shell.execute_reply": "2021-11-09T08:24:45.892858Z",
     "shell.execute_reply.started": "2021-11-09T07:54:22.907318Z"
    },
    "id": "7b511a52",
    "papermill": {
     "duration": 10.74732,
     "end_time": "2021-11-09T08:24:45.893042",
     "exception": false,
     "start_time": "2021-11-09T08:24:35.145722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_from_saved_checkpoint = load_model('my_best_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "H1F56lS_93TS",
    "HfXgO1eM90Iq",
    "rqK_xrJWVuck",
    "lLbwlWzN8P6-",
    "2JHDgEvC8Jzr",
    "RbESQNif7sFE"
   ],
   "name": "btc V0.2 (priceLog tp priceLog).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.774638,
   "end_time": "2021-11-09T08:24:56.343239",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-09T08:22:20.568601",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
